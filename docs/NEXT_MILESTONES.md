# 次のマイルストーンと優先順位

現在の到達点: 「アップロード → フレーム抽出 → pHashクラスタ → サムネ表示」をローカルで完走済み。次のステップをP0/P1で整理します。

## P0: 骨格推定 & 自動撮影
- Mediapipe Pose Landmarker を使い、ブラウザで骨格座標を取得するフローを確立
- 進行中のポーズとターゲットポーズの類似度（例: コサイン類似度）を計算
- 類似度閾値＆タイムアウトで自動シャッター（プリクラ風）を実装
- E2E: 類似度が一定以上で撮影がトリガーされることをモック含め検証

## P0: 合成（ffmpegで元動画にポーズ画像を重ねる）
- 解析で得た代表フレーム位置に、撮影した画像を同座標で合成
- 背景動画に対してフレーム単位でオーバーレイするスクリプト（ffmpegフィルタ）
- 出力: オリジナル動画と同尺の「踊ってみた」合成動画
- テスト: サンプル動画＋ダミー画像での合成結果を自動検証

## P1: デプロイ（クラウド）
- フロント: Vercel / バック: 任意（Railway/ECS等）でのデプロイ手順をドキュメント化
- 環境変数・ストレージ・Redis依存の設定手順を整理
- CI/CD で lint/test を走らせる最低限のワークフローを追加

## 補足: 調整用パラメータ
- FRAME_EXTRACT_FPS / FRAME_MAX_FRAMES で抽出密度と上限を調整
- HASH_HAMMING_THRESHOLD（ハミング閾値）を上げるとクラスタがまとまり、重複が減る

## 着手順の提案
1. 骨格推定＋類似度ロジックをブラウザで完成させ、自動シャッターを実装（P0）
2. 撮影画像の収集とメタデータ（対応する代表フレームID）の保存（P0）
3. ffmpeg 合成スクリプトを追加し、代表フレーム位置に撮影画像を重ねる（P0）
4. クラウドデプロイ手順を整備し、CI/CDで最低限の検証を回す（P1）
