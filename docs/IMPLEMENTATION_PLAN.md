# DanceFrame - å®Ÿè£…è¨ˆç”»æ›¸

**ä½œæˆæ—¥**: 2025-11-16
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0
**æ¨å®šæœŸé–“**: 15-20å–¶æ¥­æ—¥
**é–‹ç™ºè€…**: Kosuke Terada

---

## ğŸ“‹ ç›®æ¬¡

1. [å®Ÿè£…æ–¹é‡](#å®Ÿè£…æ–¹é‡)
2. [é–‹ç™ºç’°å¢ƒ](#é–‹ç™ºç’°å¢ƒ)
3. [ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…è¨ˆç”»](#ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…è¨ˆç”»)
4. [æŠ€è¡“çš„æ¤œè¨¼äº‹é …](#æŠ€è¡“çš„æ¤œè¨¼äº‹é …)
5. [ãƒªã‚¹ã‚¯ç®¡ç†](#ãƒªã‚¹ã‚¯ç®¡ç†)
6. [ãƒ‡ãƒ—ãƒ­ã‚¤è¨ˆç”»](#ãƒ‡ãƒ—ãƒ­ã‚¤è¨ˆç”»)
7. [å“è³ªä¿è¨¼](#å“è³ªä¿è¨¼)

---

## ğŸ¯ å®Ÿè£…æ–¹é‡

### é–‹ç™ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

**ã‚¢ã‚¸ãƒ£ã‚¤ãƒ«ãƒ»åå¾©å‹é–‹ç™º**

- **ã‚¹ãƒ—ãƒªãƒ³ãƒˆæœŸé–“**: 3-4æ—¥
- **åå¾©ã‚µã‚¤ã‚¯ãƒ«**: è¨­è¨ˆ â†’ å®Ÿè£… â†’ ãƒ†ã‚¹ãƒˆ â†’ ãƒ¬ãƒ“ãƒ¥ãƒ¼
- **æœ€å°æ©Ÿèƒ½å˜ä½**: å„ãƒ•ã‚§ãƒ¼ã‚ºã‚’ç‹¬ç«‹ã—ã¦å‹•ä½œå¯èƒ½ãªçŠ¶æ…‹ã§å®Œæˆã•ã›ã‚‹

### å„ªå…ˆé †ä½

1. **P0 (å¿…é ˆ)**: MVPæ©Ÿèƒ½ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€åŸºç›¤
2. **P1 (é‡è¦)**: UXæ”¹å–„ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
3. **P2 (ä»»æ„)**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€è¿½åŠ æ©Ÿèƒ½

### æŠ€è¡“é¸å®šã®æ ¹æ‹ 

| æŠ€è¡“ | é¸å®šç†ç”± | ä»£æ›¿æ¡ˆ | é¸å®šæ ¹æ‹  |
|------|---------|--------|---------|
| **MediaPipe Tasks Vision** | æœ€æ–°APIã€GPUåŠ é€Ÿã€WASMå¯¾å¿œ | TensorFlow.js PoseNet | MediaPipeã®æ–¹ãŒé«˜ç²¾åº¦ãƒ»é«˜é€Ÿï¼ˆèª¿æŸ»æ¸ˆï¼‰ |
| **Next.js 16** | Turbopackå®‰å®šç‰ˆã€React Compiler | Vite + React | SSRã€Imageæœ€é©åŒ–ã€ãƒ‡ãƒ—ãƒ­ã‚¤å®¹æ˜“æ€§ |
| **Celery** | æˆç†Ÿã—ãŸã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã€è±Šå¯Œãªæ©Ÿèƒ½ | BullMQ (Node.js) | Pythonç”Ÿæ…‹ç³»ã¨ã®è¦ªå’Œæ€§ |
| **Redis** | é«˜é€Ÿã€ã‚·ãƒ³ãƒ—ãƒ« | RabbitMQ | å°è¦æ¨¡ãªã‚‰ååˆ†ã€é‹ç”¨ã‚³ã‚¹ãƒˆä½ |
| **Zustand** | è»½é‡ï¼ˆ1KBï¼‰ã€ã‚·ãƒ³ãƒ—ãƒ«API | Redux, Jotai | å­¦ç¿’ã‚³ã‚¹ãƒˆä½ã€React 19å¯¾å¿œæ¸ˆã¿ |

---

## ğŸ–¥ï¸ é–‹ç™ºç’°å¢ƒ

### å¿…é ˆã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

| ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³• |
|------------|-----------|----------------|
| **Node.js** | 20.x LTS | `brew install node@20` |
| **Python** | 3.11+ | `brew install python@3.11` |
| **Docker** | 24.x+ | Docker Desktop |
| **Redis** | 7.2+ | `brew install redis` |
| **FFmpeg** | 6.1+ | `brew install ffmpeg` |
| **Git** | 2.40+ | æ¨™æº–æ­è¼‰ |

### æ¨å¥¨ãƒ„ãƒ¼ãƒ«

- **IDE**: VSCode + æ‹¡å¼µæ©Ÿèƒ½
  - ESLint
  - Prettier
  - Pylance (Python)
  - Tailwind CSS IntelliSense
- **API ãƒ†ã‚¹ãƒˆ**: Thunder Client / Postman
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†**: RedisInsight

### ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```bash
# .env.example

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000

# Backend
DATABASE_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
CORS_ORIGINS=http://localhost:3000,http://localhost:3001
SECRET_KEY=your-secret-key-change-this-in-production
MAX_UPLOAD_SIZE=104857600  # 100MB
FILE_RETENTION_HOURS=24

# Development
DEBUG=true
LOG_LEVEL=INFO

# Production (è¿½åŠ )
# SENTRY_DSN=...
# AWS_ACCESS_KEY_ID=...
```

---

## ğŸ“… ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…è¨ˆç”»

### Phase 0: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆ1-2æ—¥ï¼‰

#### 0.1 ãƒªãƒã‚¸ãƒˆãƒªæ§‹é€ ä½œæˆ

**ã‚¿ã‚¹ã‚¯:**
- [x] Gitãƒªãƒã‚¸ãƒˆãƒªåˆæœŸåŒ–
- [ ] ãƒ¢ãƒãƒ¬ãƒæ§‹é€ ä½œæˆ
- [ ] `.gitignore`, `.dockerignore` è¨­å®š
- [ ] README.md, LICENSEä½œæˆ

**æˆæœç‰©:**
```
dance-frame/
â”œâ”€â”€ .git/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ backend/
â””â”€â”€ docs/
    â”œâ”€â”€ SPECIFICATION_V2.md
    â”œâ”€â”€ IMPLEMENTATION_PLAN.md
    â”œâ”€â”€ ARCHITECTURE.md
    â””â”€â”€ SETUP.md
```

**æ¤œè¨¼:**
```bash
# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
tree -L 3 -I 'node_modules|__pycache__|.next'
```

---

#### 0.2 FrontendåˆæœŸåŒ–

**ã‚¿ã‚¹ã‚¯:**
- [ ] Next.js 16ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
- [ ] TypeScriptè¨­å®š
- [ ] Tailwind CSSè¨­å®š
- [ ] ESLint, Prettierè¨­å®š
- [ ] åŸºæœ¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆä½œæˆ

**ã‚³ãƒãƒ³ãƒ‰:**
```bash
cd packages/frontend

# Next.js 16 + TypeScript + Tailwind
npx create-next-app@latest . \
  --typescript \
  --tailwind \
  --app \
  --no-src-dir \
  --import-alias "@/*"

# ä¾å­˜é–¢ä¿‚è¿½åŠ 
npm install @mediapipe/tasks-vision zustand@^5.0.8 axios framer-motion

# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚
npm install -D @types/node @types/react @types/react-dom
```

**æ¤œè¨¼:**
```bash
npm run dev
# http://localhost:3000 ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦è¡¨ç¤ºç¢ºèª
```

---

#### 0.3 BackendåˆæœŸåŒ–

**ã‚¿ã‚¹ã‚¯:**
- [ ] FastAPIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ
- [ ] ä¾å­˜é–¢ä¿‚å®šç¾©ï¼ˆrequirements.txtï¼‰
- [ ] Celeryã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] Redisæ¥ç¶šç¢ºèª
- [ ] Hello World APIä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«:**
```python
# packages/backend/requirements.txt
fastapi==0.115.0
uvicorn[standard]==0.30.0
python-multipart==0.0.9
celery==5.4.0
redis==5.1.1
opencv-python==4.10.0
imagehash==4.3.1
Pillow==10.3.0
mediapipe==0.10.14
ffmpeg-python==0.2.0
pydantic==2.8.0
pydantic-settings==2.4.0
python-jose==3.3.0
aiofiles==24.1.0
python-magic==0.4.27

# Development
pytest==8.3.2
pytest-asyncio==0.23.8
pytest-cov==5.0.0
black==24.8.0
flake8==7.1.1
```

**æ¤œè¨¼:**
```bash
cd packages/backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# FastAPIèµ·å‹•ç¢ºèª
uvicorn app.main:app --reload
# http://localhost:8000/docs ã«ã‚¢ã‚¯ã‚»ã‚¹
```

---

#### 0.4 Dockerç’°å¢ƒæ§‹ç¯‰

**ã‚¿ã‚¹ã‚¯:**
- [ ] docker-compose.ymlä½œæˆ
- [ ] Frontend Dockerfileä½œæˆ
- [ ] Backend Dockerfileä½œæˆ
- [ ] Redisè¨­å®š
- [ ] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®š

**ãƒ•ã‚¡ã‚¤ãƒ«:**
```yaml
# docker-compose.yml
version: '3.8'

services:
  frontend:
    build:
      context: ./packages/frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    volumes:
      - ./packages/frontend:/app
      - /app/node_modules
      - /app/.next
    command: npm run dev
    depends_on:
      - backend

  backend:
    build:
      context: ./packages/backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CORS_ORIGINS=http://localhost:3000
    volumes:
      - ./packages/backend:/app
      - backend_uploads:/app/uploads
      - backend_outputs:/app/outputs
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    depends_on:
      - redis

  celery-worker:
    build:
      context: ./packages/backend
      dockerfile: Dockerfile
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
    volumes:
      - ./packages/backend:/app
      - backend_uploads:/app/uploads
      - backend_outputs:/app/outputs
    command: celery -A app.celery_worker worker --loglevel=info --concurrency=2
    depends_on:
      - redis
      - backend

  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru

volumes:
  redis_data:
  backend_uploads:
  backend_outputs:
```

**æ¤œè¨¼:**
```bash
docker-compose up -d
docker-compose ps  # ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒUpã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
docker-compose logs -f backend  # ãƒ­ã‚°ç¢ºèª
```

**å®Œäº†åŸºæº–:**
- âœ… ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£å¸¸èµ·å‹•
- âœ… Frontend: http://localhost:3000 ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- âœ… Backend: http://localhost:8000/docs ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- âœ… Redis: `redis-cli ping` ã§ PONG å¿œç­”

---

### Phase 1: å‹•ç”»è§£ææ©Ÿèƒ½ï¼ˆ3-4æ—¥ï¼‰

#### 1.1 ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰API

**ã‚¿ã‚¹ã‚¯:**
- [ ] `/api/upload` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
- [ ] ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
- [ ] ã‚¸ãƒ§ãƒ–IDç”Ÿæˆï¼ˆUUIDï¼‰
- [ ] ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«:**
```python
# packages/backend/app/routers/upload.py

from fastapi import APIRouter, UploadFile, File, HTTPException
from app.services.file_validator import FileValidator
from app.tasks.video_analysis import analyze_video_task
import uuid
from pathlib import Path

router = APIRouter(prefix="/api", tags=["upload"])

@router.post("/upload")
async def upload_video(file: UploadFile = File(...)):
    """
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹

    Args:
        file: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« (MP4, GIF)

    Returns:
        {"job_id": "...", "status": "processing"}
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    validator = FileValidator()
    validation_result = await validator.validate(file)

    if not validation_result.is_valid:
        raise HTTPException(400, detail=validation_result.error_message)

    # ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
    job_id = str(uuid.uuid4())

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    upload_dir = Path(f"/app/uploads/{job_id}")
    upload_dir.mkdir(parents=True, exist_ok=True)

    file_path = upload_dir / f"original{Path(file.filename).suffix}"

    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)

    # Celeryã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    task = analyze_video_task.delay(job_id, str(file_path))

    return {
        "job_id": job_id,
        "task_id": task.id,
        "status": "processing",
        "message": f"Analysis started. Check /api/analyze/{job_id} for progress."
    }
```

**ãƒ†ã‚¹ãƒˆ:**
```bash
# cURLã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
curl -X POST http://localhost:8000/api/upload \
  -F "file=@test_video.mp4" \
  -H "Content-Type: multipart/form-data"

# æœŸå¾…ãƒ¬ã‚¹ãƒãƒ³ã‚¹
# {
#   "job_id": "550e8400-e29b-41d4-a716-446655440000",
#   "status": "processing"
# }
```

---

#### 1.2 ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹

**ã‚¿ã‚¹ã‚¯:**
- [ ] FFmpegãƒ©ãƒƒãƒ‘ãƒ¼å®Ÿè£…
- [ ] éŸ³æºæŠ½å‡ºæ©Ÿèƒ½
- [ ] ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºæ©Ÿèƒ½ï¼ˆ24fpsæ­£è¦åŒ–ï¼‰
- [ ] ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆffprobeï¼‰

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«:**
```python
# packages/backend/app/services/frame_extractor.py

import ffmpeg
from pathlib import Path
from typing import Dict, List
import logging

logger = logging.getLogger(__name__)

class FrameExtractor:
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def extract_audio(self, video_path: str, output_path: str) -> bool:
        """éŸ³æºã‚’æŠ½å‡º"""
        try:
            stream = (
                ffmpeg
                .input(video_path)
                .output(
                    output_path,
                    acodec='libmp3lame',
                    ar='44100',
                    ab='192k',
                    vn=None  # æ˜ åƒãªã—
                )
                .overwrite_output()
            )
            ffmpeg.run(stream, capture_stdout=True, capture_stderr=True, quiet=True)
            logger.info(f"Audio extracted: {output_path}")
            return True

        except ffmpeg.Error as e:
            logger.error(f"Audio extraction failed: {e.stderr.decode()}")
            return False

    def extract_frames(self, video_path: str, fps: int = 24) -> Dict:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º"""
        frames_dir = self.output_dir / "frames"
        frames_dir.mkdir(exist_ok=True)

        output_pattern = str(frames_dir / "frame_%04d.png")

        try:
            # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
            stream = (
                ffmpeg
                .input(video_path)
                .filter('fps', fps=fps)
                .output(
                    output_pattern,
                    format='image2',
                    qscale=2  # é«˜å“è³ª
                )
                .overwrite_output()
            )
            ffmpeg.run(stream, capture_stdout=True, capture_stderr=True, quiet=True)

            # æŠ½å‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
            frame_files = sorted(frames_dir.glob("frame_*.png"))

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
            metadata = self.get_video_metadata(video_path)

            logger.info(f"Extracted {len(frame_files)} frames")

            return {
                'frames': [str(f) for f in frame_files],
                'count': len(frame_files),
                'fps': metadata.get('fps', fps),
                'duration': metadata.get('duration', 0),
                'resolution': metadata.get('resolution', 'unknown')
            }

        except ffmpeg.Error as e:
            logger.error(f"Frame extraction failed: {e.stderr.decode()}")
            raise

    def get_video_metadata(self, video_path: str) -> Dict:
        """å‹•ç”»ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            probe = ffmpeg.probe(video_path)

            video_stream = next(
                (s for s in probe['streams'] if s['codec_type'] == 'video'),
                None
            )

            if not video_stream:
                return {}

            # FPSè¨ˆç®—
            fps_str = video_stream.get('r_frame_rate', '24/1')
            num, den = map(int, fps_str.split('/'))
            fps = num / den if den != 0 else 24

            # è§£åƒåº¦
            width = video_stream.get('width', 0)
            height = video_stream.get('height', 0)
            resolution = f"{width}x{height}"

            # é•·ã•
            duration = float(probe['format'].get('duration', 0))

            return {
                'fps': fps,
                'duration': duration,
                'resolution': resolution,
                'width': width,
                'height': height
            }

        except Exception as e:
            logger.error(f"Metadata extraction failed: {e}")
            return {}
```

**ãƒ†ã‚¹ãƒˆ:**
```python
# tests/test_frame_extractor.py

import pytest
from app.services.frame_extractor import FrameExtractor
from pathlib import Path

def test_extract_audio(tmp_path):
    extractor = FrameExtractor(str(tmp_path))
    result = extractor.extract_audio("test_video.mp4", str(tmp_path / "audio.mp3"))
    assert result is True
    assert (tmp_path / "audio.mp3").exists()

def test_extract_frames(tmp_path):
    extractor = FrameExtractor(str(tmp_path))
    result = extractor.extract_frames("test_video.mp4", fps=24)
    assert result['count'] > 0
    assert len(result['frames']) == result['count']
```

---

#### 1.3 çŸ¥è¦šãƒãƒƒã‚·ãƒ¥è§£æ

**ã‚¿ã‚¹ã‚¯:**
- [ ] imagehashçµ±åˆ
- [ ] pHashè¨ˆç®—å®Ÿè£…
- [ ] ãƒãƒŸãƒ³ã‚°è·é›¢ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
- [ ] ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ é¸å®š

**å®Ÿè£…:**
```python
# packages/backend/app/services/hash_analyzer.py

import imagehash
from PIL import Image
from typing import List, Dict
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)

class FrameHashAnalyzer:
    def __init__(self, hamming_threshold: int = 5):
        """
        Args:
            hamming_threshold: ãƒãƒŸãƒ³ã‚°è·é›¢ã®é–¾å€¤ï¼ˆã“ã®å€¤ä»¥ä¸‹ãªã‚‰åŒä¸€ã¨ã¿ãªã™ï¼‰
        """
        self.hamming_threshold = hamming_threshold

    def analyze_frames(self, frame_paths: List[str]) -> Dict:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è§£æã—ã¦ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç‰¹å®š

        Returns:
            {
                'unique_frames': [...],  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
                'frame_mapping': {...},  # {å…ƒãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·: ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·}
                'groups': [...],         # ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±
                'total_frames': int,
                'unique_count': int
            }
        """
        logger.info(f"Analyzing {len(frame_paths)} frames...")

        # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—
        hashes = []
        for idx, path in enumerate(frame_paths):
            try:
                img = Image.open(path)
                # çŸ¥è¦šãƒãƒƒã‚·ãƒ¥ï¼ˆpHashï¼‰ã‚’è¨ˆç®—
                phash = imagehash.phash(img, hash_size=8)
                hashes.append({
                    'index': idx,
                    'path': path,
                    'hash': phash
                })
            except Exception as e:
                logger.warning(f"Failed to hash {path}: {e}")
                continue

        # é¡ä¼¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        groups = self._group_similar_frames(hashes)

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
        unique_frames = []
        frame_mapping = {}

        for group_idx, group in enumerate(groups):
            # ã‚°ãƒ«ãƒ¼ãƒ—ã®ä»£è¡¨ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
            representative = group['members'][0]
            unique_frames.append(representative['path'])

            # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
            for member in group['members']:
                frame_mapping[str(member['index'])] = group_idx

        logger.info(f"Found {len(unique_frames)} unique frames from {len(frame_paths)} total frames")

        return {
            'unique_frames': unique_frames,
            'frame_mapping': frame_mapping,
            'groups': groups,
            'total_frames': len(frame_paths),
            'unique_count': len(unique_frames)
        }

    def _group_similar_frames(self, hashes: List[Dict]) -> List[Dict]:
        """ãƒãƒƒã‚·ãƒ¥å€¤ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
        groups = []
        used = set()

        for i, hash_data in enumerate(hashes):
            if i in used:
                continue

            # æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
            group = {
                'representative': hash_data,
                'members': [hash_data]
            }
            used.add(i)

            # é¡ä¼¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¢ã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—ã«è¿½åŠ 
            for j in range(i + 1, len(hashes)):
                if j in used:
                    continue

                # ãƒãƒŸãƒ³ã‚°è·é›¢ã‚’è¨ˆç®—
                hamming_dist = hash_data['hash'] - hashes[j]['hash']

                if hamming_dist <= self.hamming_threshold:
                    group['members'].append(hashes[j])
                    used.add(j)

            groups.append(group)

        return groups
```

---

#### 1.4 éª¨æ ¼æ¨å®šã‚µãƒ¼ãƒ“ã‚¹

**ã‚¿ã‚¹ã‚¯:**
- [ ] MediaPipe Pythonç‰ˆçµ±åˆ
- [ ] 33ç‚¹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æ¤œå‡º
- [ ] ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆï¼ˆéª¨æ ¼ç·šæç”»ï¼‰
- [ ] JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

**å®Ÿè£…:**
```python
# packages/backend/app/services/pose_estimator.py

import mediapipe as mp
import cv2
import numpy as np
from PIL import Image
import base64
from io import BytesIO
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)

class PoseEstimator:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.pose = self.mp_pose.Pose(
            static_image_mode=True,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5
        )

    def estimate_pose(self, image_path: str) -> Optional[Dict]:
        """
        ç”»åƒã‹ã‚‰éª¨æ ¼æ¨å®šã‚’å®Ÿè¡Œ

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            {
                "landmarks": [
                    {"x": 0.5, "y": 0.3, "z": -0.1, "visibility": 0.99},
                    ...  # 33å€‹
                ]
            }
        """
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                logger.error(f"Failed to load image: {image_path}")
                return None

            # RGBå¤‰æ›
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # éª¨æ ¼æ¨å®šå®Ÿè¡Œ
            results = self.pose.process(image_rgb)

            if not results.pose_landmarks:
                logger.warning(f"No pose detected in {image_path}")
                return None

            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’JSONå½¢å¼ã«å¤‰æ›
            landmarks = []
            for landmark in results.pose_landmarks.landmark:
                landmarks.append({
                    'x': float(landmark.x),
                    'y': float(landmark.y),
                    'z': float(landmark.z),
                    'visibility': float(landmark.visibility)
                })

            return {'landmarks': landmarks}

        except Exception as e:
            logger.error(f"Pose estimation failed for {image_path}: {e}")
            return None

    def generate_thumbnail(
        self,
        image_path: str,
        landmarks: Optional[Dict] = None,
        size: tuple = (256, 256)
    ) -> str:
        """
        éª¨æ ¼ç·šã‚’æç”»ã—ãŸã‚µãƒ ãƒã‚¤ãƒ«ã‚’ç”Ÿæˆï¼ˆBase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰

        Args:
            image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            landmarks: éª¨æ ¼ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ï¼ˆNoneã®å ´åˆã¯å†æ¨å®šï¼‰
            size: ã‚µãƒ ãƒã‚¤ãƒ«ã‚µã‚¤ã‚º

        Returns:
            "data:image/png;base64,..." å½¢å¼ã®æ–‡å­—åˆ—
        """
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿
            image = cv2.imread(image_path)
            if image is None:
                return ""

            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒãªã„å ´åˆã¯å†æ¨å®š
            if landmarks is None:
                results = self.pose.process(image_rgb)
                if not results.pose_landmarks:
                    # éª¨æ ¼ãªã—ã§ã‚‚ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆ
                    return self._image_to_base64(Image.fromarray(image_rgb), size)
            else:
                # ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’MediaPipeå½¢å¼ã«å¤‰æ›
                landmark_list = self._dict_to_landmark_list(landmarks)
                results = type('obj', (object,), {'pose_landmarks': landmark_list})()

            # éª¨æ ¼ç·šã‚’æç”»
            annotated_image = image_rgb.copy()
            self.mp_drawing.draw_landmarks(
                annotated_image,
                results.pose_landmarks,
                self.mp_pose.POSE_CONNECTIONS,
                self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                self.mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2)
            )

            # PIL Imageã«å¤‰æ›ã—ã¦Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            pil_image = Image.fromarray(annotated_image)
            return self._image_to_base64(pil_image, size)

        except Exception as e:
            logger.error(f"Thumbnail generation failed: {e}")
            return ""

    def _image_to_base64(self, image: Image.Image, size: tuple) -> str:
        """PIL Imageã‚’Base64æ–‡å­—åˆ—ã«å¤‰æ›"""
        # ãƒªã‚µã‚¤ã‚º
        image = image.resize(size, Image.Resampling.LANCZOS)

        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()

        return f"data:image/png;base64,{img_str}"

    def _dict_to_landmark_list(self, landmarks_dict: Dict):
        """è¾æ›¸å½¢å¼ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’MediaPipeå½¢å¼ã«å¤‰æ›"""
        # TODO: å¿…è¦ã«å¿œã˜ã¦å®Ÿè£…
        pass

    def __del__(self):
        """ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾"""
        self.pose.close()
```

**å®Œäº†åŸºæº–:**
- âœ… å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰â†’è§£æâ†’çµæœå–å¾—ã®ä¸€é€£ã®æµã‚ŒãŒå‹•ä½œ
- âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒå…ƒãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã®10-30%ç¨‹åº¦
- âœ… éª¨æ ¼æ¨å®šã®æˆåŠŸç‡90%ä»¥ä¸Š
- âœ… å‡¦ç†æ™‚é–“: 10ç§’å‹•ç”»ã§30ç§’ä»¥å†…

---

### Phase 2: ã‚«ãƒ¡ãƒ©æ’®å½±æ©Ÿèƒ½ï¼ˆ3-4æ—¥ï¼‰

#### 2.1 MediaPipeçµ±åˆï¼ˆFrontendï¼‰

**ã‚¿ã‚¹ã‚¯:**
- [ ] MediaPipe Tasks VisionåˆæœŸåŒ–
- [ ] PoseLandmarkerã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒƒã‚¯å®Ÿè£…ï¼ˆuseMediaPipeï¼‰
- [ ] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éª¨æ ¼æ¨å®š

**å®Ÿè£…:**
```typescript
// packages/frontend/src/hooks/useMediaPipe.ts

import { useEffect, useRef, useState } from 'react';
import {
  PoseLandmarker,
  FilesetResolver,
  PoseLandmarkerResult
} from '@mediapipe/tasks-vision';

interface UseMediaPipeOptions {
  onResults: (results: PoseLandmarkerResult) => void;
  modelComplexity?: 0 | 1 | 2;  // 0: Lite, 1: Full, 2: Heavy
}

export function useMediaPipe(
  videoRef: React.RefObject<HTMLVideoElement>,
  options: UseMediaPipeOptions
) {
  const landmarkerRef = useRef<PoseLandmarker | null>(null);
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const animationFrameId = useRef<number>();

  useEffect(() => {
    let isMounted = true;

    async function initializeLandmarker() {
      try {
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );

        const modelName = options.modelComplexity === 0 ? 'lite' :
                          options.modelComplexity === 2 ? 'heavy' : 'full';

        const landmarker = await PoseLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_${modelName}/float16/1/pose_landmarker_${modelName}.task`,
            delegate: 'GPU'
          },
          runningMode: 'VIDEO',
          numPoses: 1,
          minPoseDetectionConfidence: 0.5,
          minPosePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        if (isMounted) {
          landmarkerRef.current = landmarker;
          setIsReady(true);
        }
      } catch (err) {
        if (isMounted) {
          setError(err instanceof Error ? err.message : 'Failed to initialize MediaPipe');
        }
      }
    }

    initializeLandmarker();

    return () => {
      isMounted = false;
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
      landmarkerRef.current?.close();
    };
  }, [options.modelComplexity]);

  // ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º
  useEffect(() => {
    if (!isReady || !videoRef.current || !landmarkerRef.current) return;

    const video = videoRef.current;
    let lastVideoTime = -1;

    async function detectPose() {
      if (!video || !landmarkerRef.current) return;

      const now = performance.now();

      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;

        try {
          const results = landmarkerRef.current.detectForVideo(video, now);
          options.onResults(results);
        } catch (err) {
          console.error('Pose detection error:', err);
        }
      }

      animationFrameId.current = requestAnimationFrame(detectPose);
    }

    detectPose();

    return () => {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
    };
  }, [isReady, videoRef, options]);

  return { isReady, error };
}
```

---

#### 2.2 ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹

**ã‚¿ã‚¹ã‚¯:**
- [ ] getUserMediaå®Ÿè£…
- [ ] ã‚«ãƒ¡ãƒ©é¸æŠæ©Ÿèƒ½ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆ/ãƒªã‚¢ï¼‰
- [ ] ã‚¹ãƒˆãƒªãƒ¼ãƒ ç®¡ç†
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**å®Ÿè£…:**
```typescript
// packages/frontend/src/hooks/useCamera.ts

import { useEffect, useRef, useState } from 'react';

interface UseCameraOptions {
  facingMode?: 'user' | 'environment';  // user: ãƒ•ãƒ­ãƒ³ãƒˆ, environment: ãƒªã‚¢
  width?: number;
  height?: number;
}

export function useCamera(options: UseCameraOptions = {}) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const [isActive, setIsActive] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const startCamera = async () => {
    try {
      const constraints: MediaStreamConstraints = {
        video: {
          facingMode: options.facingMode || 'user',
          width: { ideal: options.width || 1280 },
          height: { ideal: options.height || 720 }
        },
        audio: false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();
      }

      streamRef.current = stream;
      setIsActive(true);
      setError(null);
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Failed to access camera';
      setError(errorMessage);
      console.error('Camera error:', err);
    }
  };

  const stopCamera = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }

    setIsActive(false);
  };

  useEffect(() => {
    return () => {
      stopCamera();
    };
  }, []);

  return {
    videoRef,
    isActive,
    error,
    startCamera,
    stopCamera
  };
}
```

---

#### 2.3 ãƒãƒ¼ã‚ºãƒãƒƒãƒãƒ³ã‚°

**ã‚¿ã‚¹ã‚¯:**
- [ ] é¡ä¼¼åº¦è¨ˆç®—é–¢æ•°å®Ÿè£…
- [ ] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
- [ ] é–¾å€¤åˆ¤å®šï¼ˆ85%ï¼‰
- [ ] ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º

**å®Ÿè£…:**
ï¼ˆSPECIFICATION_V2.mdã®`calculatePoseSimilarity`ã‚’ä½¿ç”¨ï¼‰

---

#### 2.4 æ’®å½±UIå®Ÿè£…

**ã‚¿ã‚¹ã‚¯:**
- [ ] ã‚«ãƒ¡ãƒ©ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- [ ] ãƒãƒ¼ã‚ºã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º
- [ ] é¡ä¼¼åº¦ãƒ¡ãƒ¼ã‚¿ãƒ¼
- [ ] ã‚¿ã‚¤ãƒãƒ¼è¡¨ç¤º
- [ ] è‡ªå‹•ã‚·ãƒ£ãƒƒã‚¿ãƒ¼

**å®Ÿè£…:**
```typescript
// packages/frontend/src/app/capture/page.tsx

'use client';

import { useState, useRef, useCallback } from 'react';
import { useCamera } from '@/hooks/useCamera';
import { useMediaPipe } from '@/hooks/useMediaPipe';
import { calculatePoseSimilarity } from '@/lib/poseComparison';
import { useAppStore } from '@/store/useAppStore';

export default function CapturePage() {
  const { videoRef, isActive, startCamera, stopCamera } = useCamera({ facingMode: 'user' });
  const [similarity, setSimilarity] = useState(0);
  const [timeLeft, setTimeLeft] = useState(5);
  const canvasRef = useRef<HTMLCanvasElement>(null);

  const { uniqueFrames, currentPoseIndex, addCapturedImage, nextPose } = useAppStore();
  const targetPose = uniqueFrames[currentPoseIndex];

  // MediaPipeçµæœãƒãƒ³ãƒ‰ãƒ©ãƒ¼
  const handleResults = useCallback((results) => {
    if (!results.landmarks || results.landmarks.length === 0) {
      setSimilarity(0);
      return;
    }

    const currentLandmarks = results.landmarks[0];
    const targetLandmarks = targetPose.pose_landmarks.landmarks;

    // é¡ä¼¼åº¦è¨ˆç®—
    const { similarity: sim } = calculatePoseSimilarity(targetLandmarks, currentLandmarks);
    setSimilarity(sim);

    // è‡ªå‹•ã‚·ãƒ£ãƒƒã‚¿ãƒ¼ï¼ˆ85%ä»¥ä¸Šï¼‰
    if (sim >= 85) {
      captureFrame();
    }
  }, [targetPose]);

  const { isReady } = useMediaPipe(videoRef, {
    onResults: handleResults,
    modelComplexity: 1
  });

  // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£
  const captureFrame = async () => {
    if (!canvasRef.current || !videoRef.current) return;

    const canvas = canvasRef.current;
    const video = videoRef.current;

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const ctx = canvas.getContext('2d')!;
    ctx.drawImage(video, 0, 0);

    const blob = await new Promise<Blob>((resolve) => {
      canvas.toBlob((b) => resolve(b!), 'image/jpeg', 0.92);
    });

    // Zustandã«ä¿å­˜
    addCapturedImage(currentPoseIndex, blob);

    // æ¬¡ã®ãƒãƒ¼ã‚ºã¸
    setTimeout(() => {
      nextPose();
    }, 500);
  };

  return (
    <div className="min-h-screen bg-gray-900 text-white">
      {/* ãƒ˜ãƒƒãƒ€ãƒ¼ */}
      <div className="flex justify-between items-center p-4">
        <div className="text-2xl font-bold">
          é¡ä¼¼åº¦: {similarity}% {similarity >= 85 && 'ğŸ¯'}
        </div>
        <div className="text-xl">
          â±ï¸ æ®‹ã‚Š {timeLeft}ç§’
        </div>
      </div>

      {/* ã‚«ãƒ¡ãƒ©ãƒ“ãƒ¥ãƒ¼ */}
      <div className="relative flex justify-center items-center">
        <video
          ref={videoRef}
          className="max-w-full max-h-[70vh]"
          playsInline
          muted
        />
        <canvas ref={canvasRef} className="hidden" />

        {/* ç›®æ¨™ãƒãƒ¼ã‚ºã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ */}
        {targetPose && (
          <img
            src={targetPose.thumbnail}
            alt="Target pose"
            className="absolute inset-0 opacity-30 pointer-events-none"
          />
        )}
      </div>

      {/* é€²æ— */}
      <div className="text-center mt-4">
        ãƒãƒ¼ã‚º {currentPoseIndex + 1} / {uniqueFrames.length}
      </div>
    </div>
  );
}
```

**å®Œäº†åŸºæº–:**
- âœ… ã‚«ãƒ¡ãƒ©ãŒæ­£å¸¸ã«èµ·å‹•
- âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éª¨æ ¼æ¨å®šãŒ30FPSä»¥ä¸Š
- âœ… é¡ä¼¼åº¦ãŒæ­£ç¢ºã«è¨ˆç®—ã•ã‚Œã‚‹
- âœ… 85%ä»¥ä¸Šã§è‡ªå‹•ã‚·ãƒ£ãƒƒã‚¿ãƒ¼å‹•ä½œ
- âœ… æ’®å½±ç”»åƒãŒZustandã«ä¿å­˜ã•ã‚Œã‚‹

---

### Phase 3: ç¢ºèªãƒ»æ’®ã‚Šç›´ã—æ©Ÿèƒ½ï¼ˆ1æ—¥ï¼‰

#### 3.1 ã‚µãƒ ãƒã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º

**ã‚¿ã‚¹ã‚¯:**
- [ ] ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå®Ÿè£…
- [ ] æ’®å½±æ¸ˆã¿/æœªæ’®å½±ã®åˆ¤å®š
- [ ] æ‹¡å¤§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ€ãƒ«
- [ ] æ’®ã‚Šç›´ã—ãƒœã‚¿ãƒ³

**å®Ÿè£…:**
```typescript
// packages/frontend/src/app/review/page.tsx

'use client';

import { useAppStore } from '@/store/useAppStore';
import Image from 'next/image';
import { useState } from 'react';

export default function ReviewPage() {
  const { uniqueFrames, capturedImages, goToCapture } = useAppStore();
  const [selectedFrame, setSelectedFrame] = useState<number | null>(null);

  return (
    <div className="min-h-screen bg-gray-100 p-8">
      <h1 className="text-3xl font-bold mb-6">æ’®å½±å®Œäº†ï¼ç¢ºèªã—ã¦ã­ ğŸ“¸</h1>

      <div className="grid grid-cols-4 gap-4">
        {uniqueFrames.map((frame, index) => {
          const captured = capturedImages[index];
          const isCapture = !!captured;

          return (
            <div
              key={index}
              className="relative aspect-square bg-white rounded-lg shadow-md overflow-hidden cursor-pointer"
              onClick={() => setSelectedFrame(index)}
            >
              {isCapture ? (
                <>
                  <Image
                    src={URL.createObjectURL(captured)}
                    alt={`Captured ${index}`}
                    fill
                    className="object-cover"
                  />
                  <div className="absolute top-2 right-2 bg-green-500 text-white rounded-full w-8 h-8 flex items-center justify-center">
                    âœ“
                  </div>
                </>
              ) : (
                <>
                  <Image
                    src={frame.thumbnail}
                    alt={`Original ${index}`}
                    fill
                    className="object-cover opacity-30"
                  />
                  <div className="absolute top-2 right-2 bg-red-500 text-white rounded-full w-8 h-8 flex items-center justify-center">
                    âŒ
                  </div>
                  <button
                    onClick={(e) => {
                      e.stopPropagation();
                      goToCapture(index);
                    }}
                    className="absolute inset-0 flex items-center justify-center bg-black bg-opacity-50 text-white hover:bg-opacity-70"
                  >
                    æ’®å½±ã™ã‚‹
                  </button>
                </>
              )}
            </div>
          );
        })}
      </div>

      {/* ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ */}
      <div className="flex justify-between mt-8">
        <button
          onClick={() => window.history.back()}
          className="px-6 py-3 bg-gray-500 text-white rounded-lg hover:bg-gray-600"
        >
          â† æˆ»ã‚‹
        </button>
        <button
          onClick={() => {/* å‹•ç”»ç”Ÿæˆã¸ */}}
          className="px-6 py-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700"
        >
          å‹•ç”»ã‚’ç”Ÿæˆ! ğŸ¬
        </button>
      </div>

      {/* æ‹¡å¤§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ€ãƒ« */}
      {selectedFrame !== null && (
        <div
          className="fixed inset-0 bg-black bg-opacity-80 flex items-center justify-center z-50"
          onClick={() => setSelectedFrame(null)}
        >
          <Image
            src={capturedImages[selectedFrame] ? URL.createObjectURL(capturedImages[selectedFrame]) : uniqueFrames[selectedFrame].thumbnail}
            alt="Preview"
            width={800}
            height={800}
            className="max-w-full max-h-full"
          />
        </div>
      )}
    </div>
  );
}
```

---

### Phase 4: å‹•ç”»ç”Ÿæˆæ©Ÿèƒ½ï¼ˆ2æ—¥ï¼‰

#### 4.1 ç”ŸæˆAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

**ã‚¿ã‚¹ã‚¯:**
- [ ] `/api/generate` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
- [ ] Base64ç”»åƒã®ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒ»ä¿å­˜
- [ ] Celeryã‚¿ã‚¹ã‚¯èµ·å‹•
- [ ] é€²æ—é€šçŸ¥ï¼ˆWebSocketï¼‰

**å®Ÿè£…:**
```python
# packages/backend/app/routers/generate.py

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List
from app.tasks.video_composition import compose_video_task
import uuid

router = APIRouter(prefix="/api", tags=["generate"])

class CapturedFrame(BaseModel):
    unique_frame_id: int
    image: str  # "data:image/jpeg;base64,..."

class GenerateRequest(BaseModel):
    job_id: str
    captured_frames: List[CapturedFrame]

@router.post("/generate")
async def generate_video(request: GenerateRequest):
    """
    æ’®å½±ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ

    Args:
        job_id: è§£æã‚¸ãƒ§ãƒ–ID
        captured_frames: æ’®å½±ç”»åƒãƒªã‚¹ãƒˆ

    Returns:
        {"generation_id": "...", "status": "processing"}
    """
    generation_id = f"gen_{uuid.uuid4().hex[:8]}"

    # Celeryã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    task = compose_video_task.delay(
        job_id=request.job_id,
        generation_id=generation_id,
        captured_frames=[f.dict() for f in request.captured_frames]
    )

    return {
        "generation_id": generation_id,
        "task_id": task.id,
        "status": "processing",
        "message": f"Check /api/status/{generation_id} for progress"
    }
```

---

#### 4.2 å‹•ç”»åˆæˆCeleryã‚¿ã‚¹ã‚¯

**å®Ÿè£…:**
ï¼ˆSPECIFICATION_V2.mdã®`compose_video_task`ã‚’ä½¿ç”¨ï¼‰

---

### Phase 5: UI/UXæ”¹å–„ï¼ˆ1-2æ—¥ï¼‰

**ã‚¿ã‚¹ã‚¯:**
- [ ] ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] ãƒˆãƒ¼ã‚¹ãƒˆé€šçŸ¥ï¼ˆæˆåŠŸ/ã‚¨ãƒ©ãƒ¼ï¼‰
- [ ] ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
- [ ] ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸
- [ ] ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³

---

### Phase 6: ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°ï¼ˆ2-3æ—¥ï¼‰

**ã‚¿ã‚¹ã‚¯:**
- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆBackendï¼‰
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] E2Eãƒ†ã‚¹ãƒˆï¼ˆPlaywrightï¼‰
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- [ ] ãƒã‚°ä¿®æ­£

---

### Phase 7: ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆ1æ—¥ï¼‰

**ã‚¿ã‚¹ã‚¯:**
- [ ] Vercelè¨­å®šï¼ˆFrontendï¼‰
- [ ] Railwayè¨­å®šï¼ˆBackendï¼‰
- [ ] ç’°å¢ƒå¤‰æ•°è¨­å®š
- [ ] DNSè¨­å®š
- [ ] æœ¬ç•ªç¢ºèª

---

## ğŸ§ª æŠ€è¡“çš„æ¤œè¨¼äº‹é …

### æ¤œè¨¼1: MediaPipe Tasks Visionæ€§èƒ½

**ç›®çš„:** ãƒ–ãƒ©ã‚¦ã‚¶ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éª¨æ ¼æ¨å®šãŒå®Ÿç”¨çš„ãªé€Ÿåº¦ã‹æ¤œè¨¼

**æ–¹æ³•:**
```typescript
// benchmark.ts

async function benchmarkPoseEstimation() {
  const video = document.querySelector('video')!;
  const landmarker = await initializePoseLandmarker();

  const samples = 100;
  const times: number[] = [];

  for (let i = 0; i < samples; i++) {
    const start = performance.now();
    await landmarker.detectForVideo(video, start);
    const end = performance.now();
    times.push(end - start);
  }

  const avgTime = times.reduce((a, b) => a + b) / times.length;
  const fps = 1000 / avgTime;

  console.log(`Average time: ${avgTime.toFixed(2)}ms`);
  console.log(`Estimated FPS: ${fps.toFixed(1)}`);
}
```

**åˆæ ¼åŸºæº–:** 30 FPSä»¥ä¸Šï¼ˆ33msä»¥ä¸‹/ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰

---

### æ¤œè¨¼2: FFmpegå‡¦ç†é€Ÿåº¦

**ç›®çš„:** å‹•ç”»å‡¦ç†ãŒè¨±å®¹ç¯„å›²å†…ã®æ™‚é–“ã§å®Œäº†ã™ã‚‹ã‹

**æ–¹æ³•:**
```python
import time
from app.services.frame_extractor import FrameExtractor

def benchmark_ffmpeg():
    extractor = FrameExtractor("/tmp/test")

    # 10ç§’å‹•ç”»ã§ãƒ†ã‚¹ãƒˆ
    start = time.time()
    result = extractor.extract_frames("test_10s.mp4", fps=24)
    elapsed = time.time() - start

    print(f"Extracted {result['count']} frames in {elapsed:.2f}s")
    print(f"Speed: {result['count'] / elapsed:.1f} fps")

    return elapsed < 10  # 10ç§’ä»¥å†…ãªã‚‰OK
```

**åˆæ ¼åŸºæº–:** 10ç§’å‹•ç”»ã‚’10ç§’ä»¥å†…ã§å‡¦ç†

---

### æ¤œè¨¼3: çŸ¥è¦šãƒãƒƒã‚·ãƒ¥é‡è¤‡æ¤œå‡ºç²¾åº¦

**ç›®çš„:** ãƒ«ãƒ¼ãƒ—ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã§é©åˆ‡ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ¤œå‡ºã§ãã‚‹ã‹

**æ–¹æ³•:**
æ‰‹å‹•ã§ä½œæˆã—ãŸãƒ†ã‚¹ãƒˆå‹•ç”»ï¼ˆåŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç¹°ã‚Šè¿”ã•ã‚Œã‚‹ï¼‰ã§æ¤œè¨¼

**åˆæ ¼åŸºæº–:** é‡è¤‡ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’95%ä»¥ä¸Šæ­£ã—ãã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°

---

## âš ï¸ ãƒªã‚¹ã‚¯ç®¡ç†

| ãƒªã‚¹ã‚¯ | å½±éŸ¿åº¦ | å¯¾ç­– |
|--------|--------|------|
| **MediaPipeæ€§èƒ½ä¸è¶³** | é«˜ | è»½é‡ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆèª¿æ•´ |
| **FFmpegå‡¦ç†é…å»¶** | ä¸­ | GPUåŠ é€Ÿã€æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ |
| **Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ä¸å®‰å®š** | ä¸­ | ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã€ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ |
| **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ä¸è¶³** | ä½ | è‡ªå‹•å‰Šé™¤ã€åœ§ç¸® |
| **ãƒ–ãƒ©ã‚¦ã‚¶äº’æ›æ€§å•é¡Œ** | ä¸­ | ãƒãƒªãƒ•ã‚£ãƒ«ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ |

---

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤è¨ˆç”»

### Vercelï¼ˆFrontendï¼‰

```bash
# Vercelãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
cd packages/frontend
vercel

# ç’°å¢ƒå¤‰æ•°è¨­å®š
vercel env add NEXT_PUBLIC_API_URL production
# Value: https://api.danceframe.app
```

### Railwayï¼ˆBackendï¼‰

```bash
# Railwayãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
railway init

# ã‚µãƒ¼ãƒ“ã‚¹è¿½åŠ 
railway add  # Redis
railway add  # FastAPI
railway add  # Celery Worker

# ç’°å¢ƒå¤‰æ•°è¨­å®š
railway variables set REDIS_URL=redis://...
railway variables set CORS_ORIGINS=https://danceframe.app
```

---

## âœ… å“è³ªä¿è¨¼

### ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™

- Backend: 80%ä»¥ä¸Š
- Frontend: 70%ä»¥ä¸Š

### ãƒ†ã‚¹ãƒˆãƒ”ãƒ©ãƒŸãƒƒãƒ‰

```
       /\
      /E2E\      (5%)  - Playwright
     /------\
    /  çµ±åˆ  \    (15%) - API Tests
   /----------\
  / ãƒ¦ãƒ‹ãƒƒãƒˆ  \  (80%) - Jest, Pytest
 /--------------\
```

### CI/CD

```yaml
# .github/workflows/ci.yml

name: CI

on: [push, pull_request]

jobs:
  test-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: pip install -r packages/backend/requirements.txt
      - run: pytest packages/backend/tests

  test-frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '20'
      - run: npm ci
        working-directory: packages/frontend
      - run: npm test
        working-directory: packages/frontend
```

---

**Document Version**: 2.0
**Last Updated**: 2025-11-16
**Status**: Ready for Implementation
