# DanceFrame - æŠ€è¡“ä»•æ§˜æ›¸ v2.0

**æœ€çµ‚æ›´æ–°**: 2025-11-16
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0 (2025å¹´ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹å¯¾å¿œç‰ˆ)
**è‘—è€…**: Kosuke Terada & Claude

---

## ğŸ“‹ ç›®æ¬¡

1. [å¤‰æ›´å±¥æ­´](#å¤‰æ›´å±¥æ­´)
2. [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦)
3. [æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼ˆæ›´æ–°ç‰ˆï¼‰](#æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ›´æ–°ç‰ˆ)
4. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ)
5. [æ©Ÿèƒ½è¦ä»¶](#æ©Ÿèƒ½è¦ä»¶)
6. [APIä»•æ§˜](#apiä»•æ§˜)
7. [ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå®Ÿè£…](#ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå®Ÿè£…)
8. [ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ](#ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ)
9. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)
10. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)

---

## ğŸ”„ å¤‰æ›´å±¥æ­´

### v2.0 (2025-11-16) - ãƒ¡ã‚¸ãƒ£ãƒ¼ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ

#### **é‡å¤§ãªå¤‰æ›´**

1. **MediaPipeç§»è¡Œ** ğŸ”´ BREAKING CHANGE
   - `@mediapipe/pose` (éæ¨å¥¨) â†’ `@mediapipe/tasks-vision` (æœ€æ–°)
   - ç†ç”±: æ—§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯2023å¹´3æœˆã«ã‚µãƒãƒ¼ãƒˆçµ‚äº†
   - å½±éŸ¿: ãƒãƒ¼ã‚ºæ¨å®šAPIãŒå®Œå…¨ã«å¤‰æ›´

2. **Next.js & React ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰** ğŸ”´ BREAKING CHANGE
   - Next.js: 14.2.x â†’ 16.0
   - React: 18.3.1 â†’ 19.2.0
   - ç†ç”±: Turbopackå®‰å®šç‰ˆã€React Compilerå¯¾å¿œ
   - å½±éŸ¿: ãƒ“ãƒ«ãƒ‰é€Ÿåº¦5-10å€å‘ä¸Šã€è‡ªå‹•æœ€é©åŒ–

3. **ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†è¿½åŠ ** âš ï¸ ARCHITECTURE CHANGE
   - Celery + Redis ã®å°å…¥
   - ç†ç”±: CPUé›†ç´„çš„ãªå‹•ç”»å‡¦ç†ã®éåŒæœŸåŒ–
   - å½±éŸ¿: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨UXå‘ä¸Š

#### **ãƒã‚¤ãƒŠãƒ¼ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ**

- Zustand: 4.5.2 â†’ 5.0.8
- ffmpeg-python ã®é©åˆ‡ãªä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ 
- WebSocket ã«ã‚ˆã‚‹é€²æ—é€šçŸ¥æ©Ÿèƒ½

#### **å‚è€ƒè³‡æ–™**

- [MediaPipe Tasks Vision Migration Guide](https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker/web_js)
- [Next.js 16 Release Notes](https://nextjs.org/blog/next-16)
- [React 19.2 Documentation](https://react.dev/blog/2025/01/15/react-19-2)
- [FastAPI Background Tasks Best Practices](https://fastapi.tiangolo.com/tutorial/background-tasks/)

---

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

æ‰‹æããƒ«ãƒ¼ãƒ—ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ã‹ã‚‰åŸç”»ã‚’æŠ½å‡ºã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒåŒã˜ãƒãƒ¼ã‚ºã‚’æ’®å½±ã™ã‚‹ã“ã¨ã§ã€Œè‡ªåˆ†ãŒè¸Šã£ã¦ã¿ãŸã€é¢¨ã®å‹•ç”»ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚

### ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼

- **åˆæœŸï¼ˆMVPï¼‰**: é–‹ç™ºè€…æœ¬äºº
- **çŸ­æœŸï¼ˆv1.xï¼‰**: ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ
- **ä¸­æœŸï¼ˆv2.xï¼‰**: ä¸€èˆ¬SNSãƒ¦ãƒ¼ã‚¶ãƒ¼

### ä¸»è¦ãªä¾¡å€¤æä¾›

1. **è‡ªå‹•åŒ–**: æ‰‹å‹•ã§ã®ãƒ•ãƒ¬ãƒ¼ãƒ é¸å®šä¸è¦
2. **æ¥½ã—ã•**: ã‚²ãƒ¼ãƒ æ„Ÿè¦šã®æ’®å½±ä½“é¨“
3. **ã‚¯ã‚ªãƒªãƒ†ã‚£**: AIé§†å‹•ã®é«˜ç²¾åº¦ãƒãƒƒãƒãƒ³ã‚°
4. **å³æ™‚æ€§**: æ•°åˆ†ã§å®Œæˆå‹•ç”»ã‚’å–å¾—

---

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ï¼ˆæ›´æ–°ç‰ˆï¼‰

### Frontend

| æŠ€è¡“ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | é¸å®šç†ç”± | å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ |
|------|-----------|----------|-----------------|
| **Next.js** | **16.0** | âœ… Turbopackå®‰å®šç‰ˆï¼ˆ5-10å€é«˜é€ŸåŒ–ï¼‰<br>âœ… PPRï¼ˆPartial Pre-Renderingï¼‰<br>âœ… React Compilerçµ±åˆ | [nextjs.org](https://nextjs.org/blog/next-16) |
| **React** | **19.2** | âœ… View Transitions API<br>âœ… useEffectEvent ãƒ•ãƒƒã‚¯<br>âœ… è‡ªå‹•æœ€é©åŒ– | [react.dev](https://react.dev/) |
| **TypeScript** | 5.3+ | å‹å®‰å…¨æ€§ã€IDEè£œå®Œ | [typescriptlang.org](https://www.typescriptlang.org/) |
| **MediaPipe Tasks Vision** | **0.10.15** | âœ… æœ€æ–°ã®Pose Landmarker API<br>âœ… WASM + GPUåŠ é€Ÿ<br>âš ï¸ `@mediapipe/pose`ã¯éæ¨å¥¨ | [ai.google.dev](https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker/web_js) |
| **Zustand** | **5.0.8** | è»½é‡ï¼ˆ1KBï¼‰ã€ã‚·ãƒ³ãƒ—ãƒ«APIã€React 19å¯¾å¿œ | [zustand.docs.pmnd.rs](https://zustand.docs.pmnd.rs/) |
| **Tailwind CSS** | 3.4+ | ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã€JIT | [tailwindcss.com](https://tailwindcss.com/) |
| **Framer Motion** | 11.0+ | View Transitionså¯¾å¿œã€å®£è¨€çš„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ | [framer.com/motion](https://www.framer.com/motion/) |

### Backend

| æŠ€è¡“ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | é¸å®šç†ç”± | å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ |
|------|-----------|----------|-----------------|
| **FastAPI** | 0.115+ | é«˜é€Ÿã€è‡ªå‹•ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã€asyncå¯¾å¿œ | [fastapi.tiangolo.com](https://fastapi.tiangolo.com/) |
| **Celery** | **5.4** | âœ… CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯ã®éåŒæœŸå‡¦ç†<br>âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ | [docs.celeryproject.org](https://docs.celeryproject.org/) |
| **Redis** | 7.2+ | é«˜é€Ÿã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ–ãƒ­ãƒ¼ã‚«ãƒ¼ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ | [redis.io](https://redis.io/) |
| **Python** | 3.11+ | é«˜é€Ÿã€å‹ãƒ’ãƒ³ãƒˆã€è±Šå¯Œãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª | [python.org](https://www.python.org/) |
| **FFmpeg** | 6.1+ | æ¥­ç•Œæ¨™æº–ã€é«˜æ€§èƒ½å‹•ç”»å‡¦ç† | [ffmpeg.org](https://ffmpeg.org/) |
| **ffmpeg-python** | 0.2.0 | Pythonic APIã€å¯èª­æ€§ | [kkroening.github.io](https://kkroening.github.io/ffmpeg-python/) |
| **MediaPipe** | 0.10.14 | ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç‰ˆéª¨æ ¼æ¨å®š | [google.github.io/mediapipe](https://google.github.io/mediapipe/) |
| **imagehash** | 4.3.1 | çŸ¥è¦šãƒãƒƒã‚·ãƒ¥ã€é‡è¤‡æ¤œå‡º | [github.com/JohannesBuchner](https://github.com/JohannesBuchner/imagehash) |
| **OpenCV** | 4.10+ | ç”»åƒå‡¦ç†ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ | [opencv.org](https://opencv.org/) |

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“å›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Client (Browser)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Next.js 16 (App Router + React 19.2)                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  MediaPipe Tasks Vision (WASM + GPU)             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - PoseLandmarker.detectForVideo()               â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - Real-time pose estimation (30+ FPS)           â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  Zustand Store (Global State)                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - Job metadata                                  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - Captured images                               â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  - UI state                                      â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ HTTPS
                        â”‚ REST API (JSON)
                        â”‚ WebSocket (é€²æ—é€šçŸ¥)
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Vercel / Cloud Platform (Frontend)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Next.js Server (SSR + API Routes)                    â”‚  â”‚
â”‚  â”‚  - Edge Runtime                                       â”‚  â”‚
â”‚  â”‚  - Middleware (auth, rate limiting)                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Railway / Render (Backend Infrastructure)           â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI Server (Uvicorn + Gunicorn)                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  API Endpoints (async)                           â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - POST /api/upload                              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - GET  /api/analyze/{job_id}                    â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - POST /api/generate                            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - GET  /api/status/{job_id}                     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - WS   /ws/progress/{job_id}                    â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Celery Workers (CPU-bound Background Tasks)          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Worker 1: Video Analysis                        â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - extract_frames_task()                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - analyze_hashes_task()                         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - estimate_poses_task()                         â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Worker 2: Video Composition                     â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - compose_video_task()                          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  - merge_audio_task()                            â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Redis (Message Broker + Result Backend)              â”‚  â”‚
â”‚  â”‚  - Task queue: celery:tasks                           â”‚  â”‚
â”‚  â”‚  - Results: celery:results                            â”‚  â”‚
â”‚  â”‚  - Session cache: sessions:*                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  File Storage (Ephemeral)                             â”‚  â”‚
â”‚  â”‚  - /uploads/{job_id}/original.mp4                     â”‚  â”‚
â”‚  â”‚  - /outputs/{job_id}/frames/                          â”‚  â”‚
â”‚  â”‚  - /outputs/{job_id}/mapping.json                     â”‚  â”‚
â”‚  â”‚  - /outputs/{job_id}/final.mp4                        â”‚  â”‚
â”‚  â”‚  (è‡ªå‹•å‰Šé™¤: 24æ™‚é–“å¾Œ)                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è©³ç´°

#### 1. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ è§£æãƒ•ã‚§ãƒ¼ã‚º

```
[Client]
  â”‚
  â”œâ”€ 1. POST /api/upload
  â”‚   Body: multipart/form-data (video file)
  â”‚   â†“
[FastAPI]
  â”‚
  â”œâ”€ 2. Save to /uploads/{job_id}/original.mp4
  â”‚
  â”œâ”€ 3. Enqueue Celery task: analyze_video_task.delay(job_id)
  â”‚   â†“
[Celery Worker]
  â”‚
  â”œâ”€ 4. Extract audio â†’ /outputs/{job_id}/audio.mp3
  â”‚      ffmpeg.input(video).output(audio, acodec='mp3').run()
  â”‚
  â”œâ”€ 5. Extract frames â†’ /outputs/{job_id}/frames/frame_*.png
  â”‚      ffmpeg.input(video).output(pattern, vf='fps=24').run()
  â”‚
  â”œâ”€ 6. Calculate perceptual hashes (imagehash.phash)
  â”‚
  â”œâ”€ 7. Group similar frames (Hamming distance < 5)
  â”‚
  â”œâ”€ 8. Select unique representatives
  â”‚
  â”œâ”€ 9. Pose estimation (MediaPipe) on unique frames
  â”‚
  â”œâ”€ 10. Generate mapping.json
  â”‚       {
  â”‚         "frame_mapping": {0: 0, 1: 1, 2: 0, ...},
  â”‚         "unique_frames": [{id, path, landmarks}, ...],
  â”‚         "metadata": {fps, duration, ...}
  â”‚       }
  â”‚
  â””â”€ 11. Update Redis: job_status = "completed"
         Publish WebSocket: progress 100%
         â†“
[Client]
  â”‚
  â””â”€ 12. Poll GET /api/analyze/{job_id} or receive WebSocket notification
         â†’ Navigate to capture screen
```

#### 2. æ’®å½±ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ï¼‰

```
[Client Browser]
  â”‚
  â”œâ”€ 1. Initialize MediaPipe PoseLandmarker
  â”‚      const vision = await FilesetResolver.forVisionTasks(CDN_URL)
  â”‚      const landmarker = await PoseLandmarker.createFromOptions(...)
  â”‚
  â”œâ”€ 2. Start camera (getUserMedia)
  â”‚
  â”œâ”€ 3. Real-time loop (requestAnimationFrame):
  â”‚      â”‚
  â”‚      â”œâ”€ a. landmarker.detectForVideo(videoElement, timestamp)
  â”‚      â”‚     â†’ Get current pose landmarks
  â”‚      â”‚
  â”‚      â”œâ”€ b. calculatePoseSimilarity(targetPose, currentPose)
  â”‚      â”‚     â†’ Compute 3D Euclidean distance for key joints
  â”‚      â”‚     â†’ Convert to percentage (0-100%)
  â”‚      â”‚
  â”‚      â”œâ”€ c. Update UI (similarity meter, overlay)
  â”‚      â”‚
  â”‚      â””â”€ d. If similarity >= 85%:
  â”‚            - Capture canvas.toBlob()
  â”‚            - Play shutter sound
  â”‚            - Store in Zustand: capturedImages.push(blob)
  â”‚            - Auto-advance to next pose
  â”‚
  â””â”€ 4. All poses captured â†’ Navigate to review screen
```

#### 3. å‹•ç”»ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º

```
[Client]
  â”‚
  â”œâ”€ 1. POST /api/generate
  â”‚      Body: {
  â”‚        job_id,
  â”‚        captured_frames: [
  â”‚          {unique_frame_id: 0, image: "base64..."},
  â”‚          ...
  â”‚        ]
  â”‚      }
  â”‚      â†“
[FastAPI]
  â”‚
  â”œâ”€ 2. Save images â†’ /outputs/{job_id}/captured/frame_{id}.jpg
  â”‚
  â”œâ”€ 3. Enqueue: compose_video_task.delay(job_id)
  â”‚      â†“
[Celery Worker]
  â”‚
  â”œâ”€ 4. Load mapping.json
  â”‚
  â”œâ”€ 5. For each original frame index:
  â”‚      unique_id = mapping[frame_index]
  â”‚      if captured[unique_id] exists:
  â”‚        copy captured[unique_id] â†’ /composed_frames/frame_{index}.png
  â”‚      else:
  â”‚        copy original_unique[unique_id] â†’ /composed_frames/frame_{index}.png
  â”‚
  â”œâ”€ 6. Generate video from frames:
  â”‚      ffmpeg
  â”‚        .input('/composed_frames/frame_%04d.png', framerate=24)
  â”‚        .output('/temp_video.mp4', vcodec='libx264', pix_fmt='yuv420p')
  â”‚        .run()
  â”‚
  â”œâ”€ 7. Merge audio:
  â”‚      video = ffmpeg.input('/temp_video.mp4')
  â”‚      audio = ffmpeg.input('/audio.mp3')
  â”‚      ffmpeg
  â”‚        .output(video, audio, '/final.mp4', vcodec='copy', acodec='aac')
  â”‚        .run()
  â”‚
  â””â”€ 8. Update Redis: generation_status = "completed"
         â†“
[Client]
  â”‚
  â””â”€ 9. GET /api/download/{job_id}/final.mp4
         â†’ Download and play
```

---

## ğŸ¯ æ©Ÿèƒ½è¦ä»¶

### MVP (v1.0) - å¿…é ˆæ©Ÿèƒ½

#### 1. å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

**è¦ä»¶:**
- å¯¾å¿œå½¢å¼: MP4, GIF
- æœ€å¤§ã‚µã‚¤ã‚º: 100MB
- æœ€å¤§é•·ã•: 30ç§’
- æœ€å°è§£åƒåº¦: 480p
- æœ€å¤§è§£åƒåº¦: 1080p

**æ¤œè¨¼ãƒ«ãƒ¼ãƒ«:**
```python
ALLOWED_EXTENSIONS = {"mp4", "gif"}
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
MAX_DURATION = 30  # seconds

def validate_upload(file: UploadFile):
    # MIMEã‚¿ã‚¤ãƒ—ãƒã‚§ãƒƒã‚¯
    if file.content_type not in ["video/mp4", "image/gif"]:
        raise HTTPException(400, "Invalid file type")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    file.file.seek(0, 2)  # EOF
    size = file.file.tell()
    file.file.seek(0)  # Reset
    if size > MAX_FILE_SIZE:
        raise HTTPException(413, "File too large")

    # å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯ï¼ˆFFprobeï¼‰
    metadata = get_video_metadata(file)
    if metadata["duration"] > MAX_DURATION:
        raise HTTPException(400, "Video too long")
```

#### 2. å‹•ç”»è§£æ

**å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—:**

| ã‚¹ãƒ†ãƒƒãƒ— | å‡¦ç†å†…å®¹ | ä½¿ç”¨æŠ€è¡“ | æ¨å®šæ™‚é–“ |
|---------|---------|---------|---------|
| 1. éŸ³æºæŠ½å‡º | å‹•ç”»ã‹ã‚‰ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯ã‚’åˆ†é›¢ | FFmpeg | 1-2ç§’ |
| 2. ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º | 24fpsã§æ­£è¦åŒ–ã—ã¦PNGå‡ºåŠ› | FFmpeg | 3-5ç§’ |
| 3. ãƒãƒƒã‚·ãƒ¥è¨ˆç®— | çŸ¥è¦šãƒãƒƒã‚·ãƒ¥ï¼ˆpHashï¼‰è¨ˆç®— | imagehash | 2-3ç§’ |
| 4. é‡è¤‡æ¤œå‡º | ãƒãƒŸãƒ³ã‚°è·é›¢ã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚° | Python | 1ç§’ |
| 5. éª¨æ ¼æ¨å®š | ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ã§33ç‚¹æ¤œå‡º | MediaPipe | 5-10ç§’ |
| 6. ãƒãƒƒãƒ”ãƒ³ã‚°ç”Ÿæˆ | JSONå‡ºåŠ› | Python | <1ç§’ |

**å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ§‹é€ :**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "metadata": {
    "original_fps": 24,
    "duration": 5.0,
    "total_frames": 120,
    "unique_count": 12,
    "resolution": "1920x1080"
  },
  "frame_mapping": {
    "0": 0,
    "1": 1,
    "2": 0,
    "3": 2,
    ...
  },
  "unique_frames": [
    {
      "id": 0,
      "thumbnail": "data:image/png;base64,iVBORw0KG...",
      "pose_landmarks": {
        "landmarks": [
          {"x": 0.5123, "y": 0.2456, "z": -0.0123, "visibility": 0.995},
          {"x": 0.4987, "y": 0.1234, "z": -0.0234, "visibility": 0.987},
          ...  // 33 landmarks total
        ]
      }
    },
    ...
  ]
}
```

#### 3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ¼ã‚ºãƒãƒƒãƒãƒ³ã‚°

**ä»•æ§˜:**

| é …ç›® | å€¤ | æ ¹æ‹  |
|------|-----|------|
| ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ | 30+ FPS | MediaPipe WASMæ€§èƒ½ |
| é¡ä¼¼åº¦é–¾å€¤ | 85% | çµŒé¨“çš„èª¿æ•´å€¤ |
| ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ | 5ç§’/ãƒãƒ¼ã‚º | UXãƒãƒ©ãƒ³ã‚¹ |
| ã‚­ãƒ¼é–¢ç¯€ç‚¹æ•° | 13ç‚¹ | ä¸»è¦é–¢ç¯€ã®ã¿ä½¿ç”¨ |

**é¡ä¼¼åº¦è¨ˆç®—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ :**

```typescript
const KEY_POINTS = [
  0,  // nose
  11, 12, // shoulders
  13, 14, // elbows
  15, 16, // wrists
  23, 24, // hips
  25, 26, // knees
  27, 28, // ankles
];

function calculatePoseSimilarity(
  reference: PoseLandmarks,
  current: PoseLandmarks
): number {
  let totalDistance = 0;
  let validPoints = 0;

  for (const idx of KEY_POINTS) {
    const ref = reference.landmarks[idx];
    const cur = current.landmarks[idx];

    // ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if (ref.visibility < 0.5 || cur.visibility < 0.5) continue;

    // 3Dãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢
    const distance = Math.sqrt(
      (ref.x - cur.x) ** 2 +
      (ref.y - cur.y) ** 2 +
      (ref.z - cur.z) ** 2
    );

    totalDistance += distance;
    validPoints++;
  }

  if (validPoints === 0) return 0;

  const avgDistance = totalDistance / validPoints;

  // ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ï¼ˆçµŒé¨“çš„èª¿æ•´ï¼‰
  const SCALE_FACTOR = 200;
  const similarity = Math.max(0, Math.min(100, 100 - avgDistance * SCALE_FACTOR));

  return Math.round(similarity);
}
```

#### 4. è‡ªå‹•ã‚·ãƒ£ãƒƒã‚¿ãƒ¼

**ãƒ­ã‚¸ãƒƒã‚¯:**
```typescript
class AutoShutter {
  private threshold = 85;
  private cooldown = 500; // ms
  private lastCapture = 0;

  async checkAndCapture(
    similarity: number,
    videoElement: HTMLVideoElement,
    canvas: HTMLCanvasElement
  ): Promise<Blob | null> {
    const now = Date.now();

    // ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ã¯æ’®å½±ã—ãªã„
    if (now - this.lastCapture < this.cooldown) {
      return null;
    }

    // é–¾å€¤ãƒã‚§ãƒƒã‚¯
    if (similarity >= this.threshold) {
      // ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
      this.showFlash();

      // ã‚·ãƒ£ãƒƒã‚¿ãƒ¼éŸ³
      this.playSound('/sounds/shutter.mp3');

      // ã‚­ãƒ£ãƒ—ãƒãƒ£
      const blob = await this.captureFrame(videoElement, canvas);

      this.lastCapture = now;
      return blob;
    }

    return null;
  }

  private async captureFrame(
    video: HTMLVideoElement,
    canvas: HTMLCanvasElement
  ): Promise<Blob> {
    const ctx = canvas.getContext('2d')!;
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    ctx.drawImage(video, 0, 0);

    return new Promise((resolve) => {
      canvas.toBlob(
        (blob) => resolve(blob!),
        'image/jpeg',
        0.92  // é«˜å“è³ª
      );
    });
  }
}
```

#### 5. å‹•ç”»ç”Ÿæˆ

**ä»•æ§˜:**

- å‡ºåŠ›å½¢å¼: MP4 (H.264 + AAC)
- ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆ: 2Mbps (å‹•ç”»), 192kbps (éŸ³å£°)
- è§£åƒåº¦: å…ƒå‹•ç”»ã¨åŒã˜
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ: 24fps

**å®Ÿè£…:**
```python
def compose_video(
    job_id: str,
    frame_mapping: Dict[int, int],
    unique_frames: List[str],
    captured_images: Dict[int, str],
    audio_path: str,
    output_path: str,
    fps: int = 24
) -> str:
    composed_dir = Path(f"/tmp/{job_id}/composed")
    composed_dir.mkdir(parents=True, exist_ok=True)

    # ãƒ•ãƒ¬ãƒ¼ãƒ é…ç½®
    for frame_idx, unique_id in frame_mapping.items():
        source = captured_images.get(unique_id) or unique_frames[unique_id]
        dest = composed_dir / f"frame_{frame_idx:04d}.png"
        shutil.copy(source, dest)

    # å‹•ç”»ç”Ÿæˆï¼ˆéŸ³å£°ãªã—ï¼‰
    temp_video = f"/tmp/{job_id}/temp.mp4"
    (
        ffmpeg
        .input(str(composed_dir / "frame_%04d.png"), framerate=fps)
        .output(
            temp_video,
            vcodec='libx264',
            pix_fmt='yuv420p',
            video_bitrate='2M',
            preset='medium'
        )
        .overwrite_output()
        .run(capture_stdout=True, capture_stderr=True)
    )

    # éŸ³å£°ãƒãƒ¼ã‚¸
    video_stream = ffmpeg.input(temp_video)
    audio_stream = ffmpeg.input(audio_path)
    (
        ffmpeg
        .output(
            video_stream,
            audio_stream,
            output_path,
            vcodec='copy',
            acodec='aac',
            audio_bitrate='192k',
            shortest=None  # çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹
        )
        .overwrite_output()
        .run(capture_stdout=True, capture_stderr=True)
    )

    return output_path
```

---

## ğŸ”Œ APIä»•æ§˜

### Base URL

- **é–‹ç™º**: `http://localhost:8000`
- **æœ¬ç•ª**: `https://api.danceframe.app`

### èªè¨¼

**v1.0**: èªè¨¼ãªã—ï¼ˆå˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ³å®šï¼‰
**v2.0ä»¥é™**: JWT Bearer Token

### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä¸€è¦§

#### 1. POST /api/upload

**å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã‚’é–‹å§‹**

**Request:**
```http
POST /api/upload HTTP/1.1
Content-Type: multipart/form-data

------WebKitFormBoundary
Content-Disposition: form-data; name="file"; filename="dance.mp4"
Content-Type: video/mp4

[binary data]
------WebKitFormBoundary--
```

**Response (202 Accepted):**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "processing",
  "message": "Analysis started. Check /api/analyze/{job_id} for progress."
}
```

**Error Responses:**
```json
// 400 Bad Request
{
  "detail": "Invalid file type. Allowed: mp4, gif"
}

// 413 Payload Too Large
{
  "detail": "File size exceeds 100MB limit"
}

// 422 Unprocessable Entity
{
  "detail": "Video duration exceeds 30s limit"
}
```

---

#### 2. GET /api/analyze/{job_id}

**è§£æã‚¸ãƒ§ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¨çµæœã‚’å–å¾—**

**Request:**
```http
GET /api/analyze/550e8400-e29b-41d4-a716-446655440000 HTTP/1.1
```

**Response (200 OK) - Processing:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "processing",
  "progress": 65,
  "current_step": "Estimating poses...",
  "eta_seconds": 15
}
```

**Response (200 OK) - Completed:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "progress": 100,
  "metadata": {
    "original_fps": 24,
    "duration": 5.0,
    "total_frames": 120,
    "unique_count": 12,
    "resolution": "1920x1080"
  },
  "frame_mapping": {
    "0": 0,
    "1": 1,
    "2": 0
    // ... 120 entries
  },
  "unique_frames": [
    {
      "id": 0,
      "thumbnail": "data:image/png;base64,iVBORw0KG...",
      "pose_landmarks": {
        "landmarks": [
          {"x": 0.5, "y": 0.3, "z": -0.1, "visibility": 0.99},
          // ... 33 landmarks
        ]
      }
    }
    // ... 12 unique frames
  ]
}
```

**Error Responses:**
```json
// 404 Not Found
{
  "detail": "Job not found"
}

// 500 Internal Server Error
{
  "detail": "Analysis failed: FFmpeg error",
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "error_log": "..."
}
```

---

#### 3. POST /api/generate

**æ’®å½±ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ**

**Request:**
```http
POST /api/generate HTTP/1.1
Content-Type: application/json

{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "captured_frames": [
    {
      "unique_frame_id": 0,
      "image": "data:image/jpeg;base64,/9j/4AAQSkZJRg..."
    },
    {
      "unique_frame_id": 1,
      "image": "data:image/jpeg;base64,/9j/4AAQSkZJRg..."
    }
    // ... captured images
  ]
}
```

**Response (202 Accepted):**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "generation_id": "gen_abc123",
  "status": "processing",
  "message": "Video generation started. Check /api/status/{generation_id}"
}
```

---

#### 4. GET /api/status/{generation_id}

**å‹•ç”»ç”Ÿæˆã®é€²æ—ã‚’å–å¾—**

**Request:**
```http
GET /api/status/gen_abc123 HTTP/1.1
```

**Response (200 OK) - Processing:**
```json
{
  "generation_id": "gen_abc123",
  "status": "processing",
  "progress": 75,
  "current_step": "Merging audio...",
  "eta_seconds": 8
}
```

**Response (200 OK) - Completed:**
```json
{
  "generation_id": "gen_abc123",
  "status": "completed",
  "progress": 100,
  "video_url": "/api/download/550e8400-e29b-41d4-a716-446655440000/final.mp4",
  "video_size_bytes": 15728640,
  "duration_seconds": 5.0
}
```

---

#### 5. GET /api/download/{job_id}/final.mp4

**å®Œæˆå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**

**Request:**
```http
GET /api/download/550e8400-e29b-41d4-a716-446655440000/final.mp4 HTTP/1.1
```

**Response (200 OK):**
```http
HTTP/1.1 200 OK
Content-Type: video/mp4
Content-Length: 15728640
Content-Disposition: attachment; filename="dance_550e8400.mp4"
Cache-Control: public, max-age=3600

[binary video data]
```

---

#### 6. WebSocket: /ws/progress/{job_id}

**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**

**Connection:**
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/progress/550e8400-e29b-41d4-a716-446655440000');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data);
  // {
  //   "type": "progress",
  //   "progress": 65,
  //   "step": "Estimating poses...",
  //   "eta": 15
  // }
};
```

---

## ğŸ’» ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå®Ÿè£…

### Frontend: MediaPipe PoseLandmarkerçµ±åˆï¼ˆv2.0å¯¾å¿œï¼‰

```typescript
// packages/frontend/src/hooks/useMediaPipe.ts

import { useEffect, useRef, useState } from 'react';
import {
  PoseLandmarker,
  FilesetResolver,
  PoseLandmarkerResult
} from '@mediapipe/tasks-vision';

interface UseMediaPipeOptions {
  onResults: (results: PoseLandmarkerResult) => void;
  modelComplexity?: 0 | 1 | 2;  // 0: Lite, 1: Full, 2: Heavy
  runningMode?: 'IMAGE' | 'VIDEO';
}

export function useMediaPipe(
  videoRef: React.RefObject<HTMLVideoElement>,
  options: UseMediaPipeOptions
) {
  const landmarkerRef = useRef<PoseLandmarker | null>(null);
  const [isReady, setIsReady] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const animationFrameId = useRef<number>();

  useEffect(() => {
    let isMounted = true;

    async function initializeLandmarker() {
      try {
        // Vision tasksç”¨ã®wasmãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );

        // PoseLandmarkerã‚’ä½œæˆ
        const landmarker = await PoseLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_${
              options.modelComplexity === 0 ? 'lite' :
              options.modelComplexity === 2 ? 'heavy' : 'full'
            }/float16/1/pose_landmarker_${
              options.modelComplexity === 0 ? 'lite' :
              options.modelComplexity === 2 ? 'heavy' : 'full'
            }.task`,
            delegate: 'GPU'  // GPUåŠ é€Ÿã‚’æœ‰åŠ¹åŒ–
          },
          runningMode: options.runningMode || 'VIDEO',
          numPoses: 1,  // 1äººã®ãƒãƒ¼ã‚ºã®ã¿æ¤œå‡º
          minPoseDetectionConfidence: 0.5,
          minPosePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        if (isMounted) {
          landmarkerRef.current = landmarker;
          setIsReady(true);
        }
      } catch (err) {
        if (isMounted) {
          setError(err instanceof Error ? err.message : 'Failed to initialize MediaPipe');
        }
      }
    }

    initializeLandmarker();

    return () => {
      isMounted = false;
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
      landmarkerRef.current?.close();
    };
  }, [options.modelComplexity, options.runningMode]);

  // ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œå‡º
  useEffect(() => {
    if (!isReady || !videoRef.current || !landmarkerRef.current) return;

    const video = videoRef.current;
    let lastVideoTime = -1;

    async function detectPose() {
      if (!video || !landmarkerRef.current) return;

      const now = performance.now();

      // æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ã®å ´åˆã®ã¿å‡¦ç†
      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;

        try {
          const results = landmarkerRef.current.detectForVideo(video, now);
          options.onResults(results);
        } catch (err) {
          console.error('Pose detection error:', err);
        }
      }

      // æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
      animationFrameId.current = requestAnimationFrame(detectPose);
    }

    // æ¤œå‡ºãƒ«ãƒ¼ãƒ—é–‹å§‹
    detectPose();

    return () => {
      if (animationFrameId.current) {
        cancelAnimationFrame(animationFrameId.current);
      }
    };
  }, [isReady, videoRef, options]);

  return { isReady, error };
}
```

### Frontend: ãƒãƒ¼ã‚ºé¡ä¼¼åº¦è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰

```typescript
// packages/frontend/src/lib/poseComparison.ts

import { PoseLandmarkerResult, NormalizedLandmark } from '@mediapipe/tasks-vision';

// MediaPipe Pose ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
// https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker
const LANDMARK_INDICES = {
  NOSE: 0,
  LEFT_SHOULDER: 11,
  RIGHT_SHOULDER: 12,
  LEFT_ELBOW: 13,
  RIGHT_ELBOW: 14,
  LEFT_WRIST: 15,
  RIGHT_WRIST: 16,
  LEFT_HIP: 23,
  RIGHT_HIP: 24,
  LEFT_KNEE: 25,
  RIGHT_KNEE: 26,
  LEFT_ANKLE: 27,
  RIGHT_ANKLE: 28,
};

const KEY_POINTS = Object.values(LANDMARK_INDICES);

export interface PoseComparisonResult {
  similarity: number;  // 0-100
  details: {
    validPoints: number;
    averageDistance: number;
    maxDistance: number;
    minDistance: number;
  };
}

/**
 * 2ã¤ã®ãƒãƒ¼ã‚ºã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
 *
 * @param reference ç›®æ¨™ãƒãƒ¼ã‚ºï¼ˆå…ƒå‹•ç”»ã‹ã‚‰æŠ½å‡ºï¼‰
 * @param current ç¾åœ¨ã®ãƒãƒ¼ã‚ºï¼ˆã‚«ãƒ¡ãƒ©ã‹ã‚‰å–å¾—ï¼‰
 * @returns é¡ä¼¼åº¦ï¼ˆ0-100%ï¼‰ã¨è©³ç´°æƒ…å ±
 */
export function calculatePoseSimilarity(
  reference: NormalizedLandmark[],
  current: NormalizedLandmark[]
): PoseComparisonResult {
  if (!reference?.length || !current?.length) {
    return {
      similarity: 0,
      details: { validPoints: 0, averageDistance: 1, maxDistance: 1, minDistance: 1 }
    };
  }

  const distances: number[] = [];

  for (const idx of KEY_POINTS) {
    const ref = reference[idx];
    const cur = current[idx];

    // ä¿¡é ¼åº¦ãŒä½ã„ç‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—
    if (!ref || !cur || ref.visibility < 0.5 || cur.visibility < 0.5) {
      continue;
    }

    // 3Dãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’è¨ˆç®—
    const distance = Math.sqrt(
      Math.pow(ref.x - cur.x, 2) +
      Math.pow(ref.y - cur.y, 2) +
      Math.pow(ref.z - cur.z, 2)
    );

    distances.push(distance);
  }

  if (distances.length === 0) {
    return {
      similarity: 0,
      details: { validPoints: 0, averageDistance: 1, maxDistance: 1, minDistance: 1 }
    };
  }

  const avgDistance = distances.reduce((a, b) => a + b, 0) / distances.length;
  const maxDistance = Math.max(...distances);
  const minDistance = Math.min(...distances);

  // ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ï¼ˆçµŒé¨“çš„ã«èª¿æ•´ï¼‰
  // å¹³å‡è·é›¢0.005ã§é¡ä¼¼åº¦100%, 0.01ã§50%, 0.015ã§0%ç¨‹åº¦
  const SCALE_FACTOR = 200;
  const similarity = Math.max(0, Math.min(100, 100 - avgDistance * SCALE_FACTOR));

  return {
    similarity: Math.round(similarity),
    details: {
      validPoints: distances.length,
      averageDistance: avgDistance,
      maxDistance,
      minDistance
    }
  };
}

/**
 * è§’åº¦ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦è¨ˆç®—ï¼ˆè£œåŠ©çš„ï¼‰
 * ã‚ˆã‚Šå³å¯†ãªåˆ¤å®šãŒå¿…è¦ãªå ´åˆã«ä½¿ç”¨
 */
export function calculateAngleSimilarity(
  reference: NormalizedLandmark[],
  current: NormalizedLandmark[]
): number {
  // ä¸»è¦ãªé–¢ç¯€è§’åº¦ã‚’è¨ˆç®—
  const angles = [
    // å·¦è‚˜ã®è§’åº¦
    { joint: LANDMARK_INDICES.LEFT_ELBOW, prev: LANDMARK_INDICES.LEFT_SHOULDER, next: LANDMARK_INDICES.LEFT_WRIST },
    // å³è‚˜ã®è§’åº¦
    { joint: LANDMARK_INDICES.RIGHT_ELBOW, prev: LANDMARK_INDICES.RIGHT_SHOULDER, next: LANDMARK_INDICES.RIGHT_WRIST },
    // å·¦è†ã®è§’åº¦
    { joint: LANDMARK_INDICES.LEFT_KNEE, prev: LANDMARK_INDICES.LEFT_HIP, next: LANDMARK_INDICES.LEFT_ANKLE },
    // å³è†ã®è§’åº¦
    { joint: LANDMARK_INDICES.RIGHT_KNEE, prev: LANDMARK_INDICES.RIGHT_HIP, next: LANDMARK_INDICES.RIGHT_ANKLE },
  ];

  let totalAngleDiff = 0;
  let validAngles = 0;

  for (const { joint, prev, next } of angles) {
    const refAngle = calculateAngle(reference[prev], reference[joint], reference[next]);
    const curAngle = calculateAngle(current[prev], current[joint], current[next]);

    if (refAngle !== null && curAngle !== null) {
      const diff = Math.abs(refAngle - curAngle);
      totalAngleDiff += Math.min(diff, 360 - diff);  // è§’åº¦å·®ã®æœ€å°å€¤
      validAngles++;
    }
  }

  if (validAngles === 0) return 0;

  const avgAngleDiff = totalAngleDiff / validAngles;

  // è§’åº¦å·®0åº¦ã§100%, 45åº¦ã§50%, 90åº¦ã§0%
  const similarity = Math.max(0, 100 - (avgAngleDiff / 90) * 100);

  return Math.round(similarity);
}

function calculateAngle(
  a: NormalizedLandmark,
  b: NormalizedLandmark,
  c: NormalizedLandmark
): number | null {
  if (!a || !b || !c) return null;

  const radians = Math.atan2(c.y - b.y, c.x - b.x) - Math.atan2(a.y - b.y, a.x - b.x);
  let angle = Math.abs(radians * 180.0 / Math.PI);

  if (angle > 180.0) {
    angle = 360 - angle;
  }

  return angle;
}
```

### Backend: Celeryã‚¿ã‚¹ã‚¯å®šç¾©

```python
# packages/backend/app/celery_worker.py

from celery import Celery
from celery.signals import task_prerun, task_postrun
from app.config import settings
import logging

# Celeryã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
celery_app = Celery(
    'danceframe',
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Asia/Tokyo',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    task_soft_time_limit=540,  # 9åˆ†ã‚½ãƒ•ãƒˆãƒªãƒŸãƒƒãƒˆ
    worker_prefetch_multiplier=1,  # 1ã‚¿ã‚¹ã‚¯ãšã¤å‡¦ç†
    worker_max_tasks_per_child=50,  # 50ã‚¿ã‚¹ã‚¯ã”ã¨ã«ãƒ¯ãƒ¼ã‚«ãƒ¼å†èµ·å‹•
)

logger = logging.getLogger(__name__)

@task_prerun.connect
def task_prerun_handler(task_id, task, *args, **kwargs):
    logger.info(f"Task {task.name} [{task_id}] started")

@task_postrun.connect
def task_postrun_handler(task_id, task, *args, **kwargs):
    logger.info(f"Task {task.name} [{task_id}] completed")
```

```python
# packages/backend/app/tasks/video_analysis.py

from app.celery_worker import celery_app
from app.services.frame_extractor import FrameExtractor
from app.services.hash_analyzer import FrameHashAnalyzer
from app.services.pose_estimator import PoseEstimator
from pathlib import Path
import json
import logging

logger = logging.getLogger(__name__)

@celery_app.task(bind=True, name='tasks.analyze_video')
def analyze_video_task(self, job_id: str, video_path: str):
    """
    å‹•ç”»è§£æã‚¿ã‚¹ã‚¯

    Args:
        job_id: ã‚¸ãƒ§ãƒ–ID
        video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        dict: è§£æçµæœ
    """
    try:
        output_dir = Path(f"/app/outputs/{job_id}")
        output_dir.mkdir(parents=True, exist_ok=True)

        # ã‚¹ãƒ†ãƒƒãƒ—1: éŸ³æºæŠ½å‡º
        self.update_state(state='PROGRESS', meta={'step': 'Extracting audio', 'progress': 10})
        extractor = FrameExtractor(str(output_dir))
        audio_path = output_dir / "audio.mp3"
        extractor.extract_audio(video_path, str(audio_path))

        # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
        self.update_state(state='PROGRESS', meta={'step': 'Extracting frames', 'progress': 25})
        frame_data = extractor.extract_frames(video_path)

        # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒƒã‚·ãƒ¥è§£æ
        self.update_state(state='PROGRESS', meta={'step': 'Analyzing duplicates', 'progress': 45})
        analyzer = FrameHashAnalyzer(hamming_threshold=5)
        hash_result = analyzer.analyze_frames(frame_data['frames'])

        # ã‚¹ãƒ†ãƒƒãƒ—4: éª¨æ ¼æ¨å®š
        self.update_state(state='PROGRESS', meta={'step': 'Estimating poses', 'progress': 60})
        estimator = PoseEstimator()
        unique_frames_with_poses = []

        for i, frame_path in enumerate(hash_result['unique_frames']):
            progress = 60 + int((i / len(hash_result['unique_frames'])) * 30)
            self.update_state(
                state='PROGRESS',
                meta={'step': f'Pose estimation {i+1}/{len(hash_result["unique_frames"])}', 'progress': progress}
            )

            landmarks = estimator.estimate_pose(frame_path)
            thumbnail = estimator.generate_thumbnail(frame_path, landmarks)

            unique_frames_with_poses.append({
                'id': i,
                'path': frame_path,
                'thumbnail': thumbnail,
                'pose_landmarks': landmarks
            })

        # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒãƒƒãƒ”ãƒ³ã‚°JSONç”Ÿæˆ
        self.update_state(state='PROGRESS', meta={'step': 'Generating mapping', 'progress': 95})
        result = {
            'job_id': job_id,
            'status': 'completed',
            'metadata': {
                'original_fps': frame_data['fps'],
                'duration': frame_data['duration'],
                'total_frames': hash_result['total_frames'],
                'unique_count': hash_result['unique_count']
            },
            'frame_mapping': hash_result['frame_mapping'],
            'unique_frames': unique_frames_with_poses
        }

        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        mapping_path = output_dir / "mapping.json"
        with open(mapping_path, 'w') as f:
            json.dump(result, f, indent=2)

        return result

    except Exception as e:
        logger.error(f"Analysis task failed for job {job_id}: {e}", exc_info=True)
        raise
```

```python
# packages/backend/app/tasks/video_composition.py

from app.celery_worker import celery_app
from app.services.video_composer import VideoComposer
from pathlib import Path
import json
import base64
import logging

logger = logging.getLogger(__name__)

@celery_app.task(bind=True, name='tasks.compose_video')
def compose_video_task(self, job_id: str, captured_frames: list):
    """
    å‹•ç”»åˆæˆã‚¿ã‚¹ã‚¯

    Args:
        job_id: ã‚¸ãƒ§ãƒ–ID
        captured_frames: æ’®å½±ç”»åƒãƒªã‚¹ãƒˆ
            [{"unique_frame_id": 0, "image": "base64..."}, ...]

    Returns:
        dict: ç”Ÿæˆçµæœ
    """
    try:
        output_dir = Path(f"/app/outputs/{job_id}")

        # ãƒãƒƒãƒ”ãƒ³ã‚°èª­ã¿è¾¼ã¿
        mapping_path = output_dir / "mapping.json"
        with open(mapping_path, 'r') as f:
            mapping_data = json.load(f)

        # æ’®å½±ç”»åƒã‚’ä¿å­˜
        self.update_state(state='PROGRESS', meta={'step': 'Saving captured images', 'progress': 10})
        captured_dir = output_dir / "captured"
        captured_dir.mkdir(exist_ok=True)

        captured_paths = {}
        for item in captured_frames:
            unique_id = item['unique_frame_id']
            image_data = item['image'].split(',')[1]  # "data:image/jpeg;base64," ã‚’é™¤å»
            image_bytes = base64.b64decode(image_data)

            image_path = captured_dir / f"frame_{unique_id}.jpg"
            with open(image_path, 'wb') as f:
                f.write(image_bytes)

            captured_paths[unique_id] = str(image_path)

        # å‹•ç”»åˆæˆ
        self.update_state(state='PROGRESS', meta={'step': 'Composing video', 'progress': 40})
        composer = VideoComposer(str(output_dir))

        unique_frame_paths = [frame['path'] for frame in mapping_data['unique_frames']]
        audio_path = str(output_dir / "audio.mp3")
        final_video_path = str(output_dir / "final.mp4")

        composer.compose_video(
            job_id=job_id,
            frame_mapping=mapping_data['frame_mapping'],
            unique_frames=unique_frame_paths,
            captured_images=captured_paths,
            audio_path=audio_path,
            output_path=final_video_path,
            fps=int(mapping_data['metadata']['original_fps']),
            progress_callback=lambda p: self.update_state(
                state='PROGRESS',
                meta={'step': 'Encoding video', 'progress': 40 + int(p * 0.55)}
            )
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
        file_size = Path(final_video_path).stat().st_size

        return {
            'status': 'completed',
            'video_path': final_video_path,
            'video_size_bytes': file_size,
            'duration_seconds': mapping_data['metadata']['duration']
        }

    except Exception as e:
        logger.error(f"Composition task failed for job {job_id}: {e}", exc_info=True)
        raise
```

### Backend: ffmpeg-pythonæ´»ç”¨

```python
# packages/backend/app/services/video_composer.py (æ”¹è‰¯ç‰ˆ)

import ffmpeg
from pathlib import Path
from typing import Dict, List, Callable, Optional
import logging

logger = logging.getLogger(__name__)

class VideoComposer:
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def compose_video(
        self,
        job_id: str,
        frame_mapping: Dict[int, int],
        unique_frames: List[str],
        captured_images: Dict[int, str],
        audio_path: str,
        output_path: str,
        fps: int = 24,
        progress_callback: Optional[Callable[[float], None]] = None
    ) -> str:
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ã«åŸºã¥ã„ã¦å‹•ç”»ã‚’åˆæˆ
        """
        logger.info(f"Starting video composition for job {job_id}")

        # ãƒ•ãƒ¬ãƒ¼ãƒ é…ç½®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        composed_dir = self.output_dir / "composed_frames"
        composed_dir.mkdir(exist_ok=True)

        # ãƒ•ãƒ¬ãƒ¼ãƒ é…ç½®ï¼ˆé€²æ—20%ï¼‰
        total_frames = len(frame_mapping)
        for i, (frame_idx, unique_id) in enumerate(frame_mapping.items()):
            # æ’®å½±ç”»åƒãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°å…ƒç”»åƒ
            source_path = captured_images.get(unique_id) or unique_frames[unique_id]
            dest_path = composed_dir / f"frame_{int(frame_idx):04d}.png"

            self._copy_and_resize(source_path, dest_path)

            if progress_callback and i % 10 == 0:
                progress = 0.2 * (i / total_frames)
                progress_callback(progress)

        if progress_callback:
            progress_callback(0.2)

        # å‹•ç”»ç”Ÿæˆï¼ˆé€²æ—20-70%ï¼‰
        temp_video = self.output_dir / f"{job_id}_temp.mp4"
        self._create_video_from_frames(
            frames_dir=composed_dir,
            output_path=temp_video,
            fps=fps,
            progress_callback=lambda p: progress_callback(0.2 + 0.5 * p) if progress_callback else None
        )

        # éŸ³å£°ãƒãƒ¼ã‚¸ï¼ˆé€²æ—70-100%ï¼‰
        self._merge_audio(
            video_path=temp_video,
            audio_path=audio_path,
            output_path=output_path,
            progress_callback=lambda p: progress_callback(0.7 + 0.3 * p) if progress_callback else None
        )

        logger.info(f"Video composition completed: {output_path}")
        return output_path

    def _copy_and_resize(
        self,
        source: str,
        destination: Path,
        target_size: Optional[tuple] = None
    ):
        """
        ç”»åƒã‚’ã‚³ãƒ”ãƒ¼ï¼†ãƒªã‚µã‚¤ã‚ºï¼ˆffmpegä½¿ç”¨ï¼‰
        """
        try:
            stream = ffmpeg.input(source)

            if target_size:
                stream = ffmpeg.filter(stream, 'scale', target_size[0], target_size[1])

            stream = ffmpeg.output(stream, str(destination), format='png')
            ffmpeg.run(stream, overwrite_output=True, capture_stdout=True, capture_stderr=True, quiet=True)

        except ffmpeg.Error as e:
            logger.error(f"FFmpeg error in copy_and_resize: {e.stderr.decode()}")
            raise

    def _create_video_from_frames(
        self,
        frames_dir: Path,
        output_path: Path,
        fps: int,
        progress_callback: Optional[Callable[[float], None]] = None
    ):
        """
        ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ
        """
        input_pattern = str(frames_dir / "frame_%04d.png")

        try:
            stream = (
                ffmpeg
                .input(input_pattern, framerate=fps)
                .output(
                    str(output_path),
                    vcodec='libx264',
                    pix_fmt='yuv420p',
                    preset='medium',  # medium/fast/faster/veryfast
                    crf=23,  # å“è³ª (18-28, ä½ã„ã»ã©é«˜å“è³ª)
                    video_bitrate='2M'
                )
                .overwrite_output()
            )

            # é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ä»˜ãå®Ÿè¡Œ
            process = (
                stream
                .global_args('-progress', 'pipe:1')
                .run_async(pipe_stdout=True, pipe_stderr=True)
            )

            # é€²æ—ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if progress_callback:
                for line in process.stdout:
                    # TODO: FFmpegã®é€²æ—å‡ºåŠ›ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ­£ç¢ºãªé€²æ—ã‚’è¨ˆç®—
                    pass

            process.wait()

            if progress_callback:
                progress_callback(1.0)

        except ffmpeg.Error as e:
            logger.error(f"FFmpeg error in create_video: {e.stderr.decode()}")
            raise

    def _merge_audio(
        self,
        video_path: Path,
        audio_path: str,
        output_path: str,
        progress_callback: Optional[Callable[[float], None]] = None
    ):
        """
        å‹•ç”»ã«éŸ³å£°ã‚’è¿½åŠ 
        """
        try:
            video_stream = ffmpeg.input(str(video_path))
            audio_stream = ffmpeg.input(audio_path)

            stream = (
                ffmpeg
                .output(
                    video_stream,
                    audio_stream,
                    output_path,
                    vcodec='copy',  # ãƒ“ãƒ‡ã‚ªã¯å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãªã„
                    acodec='aac',
                    audio_bitrate='192k',
                    shortest=None  # çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹
                )
                .overwrite_output()
            )

            ffmpeg.run(stream, capture_stdout=True, capture_stderr=True)

            if progress_callback:
                progress_callback(1.0)

        except ffmpeg.Error as e:
            logger.error(f"FFmpeg error in merge_audio: {e.stderr.decode()}")
            raise
```

---

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

### v1.0: Redisï¼ˆæ®ç™ºæ€§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼‰

**Job State**
```
Key: job:{job_id}:state
Type: Hash
Fields:
  - status: "pending" | "processing" | "completed" | "failed"
  - progress: 0-100
  - current_step: "Extracting frames..."
  - created_at: timestamp
  - updated_at: timestamp
  - error: null | error_message
TTL: 24 hours
```

**Job Result**
```
Key: job:{job_id}:result
Type: String (JSON)
Value: {mapping.json content}
TTL: 24 hours
```

**Generation State**
```
Key: gen:{generation_id}:state
Type: Hash
Fields:
  - status: "pending" | "processing" | "completed" | "failed"
  - job_id: parent job ID
  - progress: 0-100
  - video_path: "/outputs/{job_id}/final.mp4"
  - created_at: timestamp
TTL: 24 hours
```

### v2.0ä»¥é™: PostgreSQLï¼ˆæ°¸ç¶šåŒ–ï¼‰

```sql
-- ãƒ¦ãƒ¼ã‚¶ãƒ¼
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(50) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ã‚¸ãƒ§ãƒ–
CREATE TABLE jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    original_filename VARCHAR(255) NOT NULL,
    file_size_bytes BIGINT NOT NULL,
    duration_seconds FLOAT,
    fps INTEGER,
    resolution VARCHAR(20),  -- "1920x1080"
    status VARCHAR(20) NOT NULL,  -- pending/processing/completed/failed
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP
);

CREATE INDEX idx_jobs_user_id ON jobs(user_id);
CREATE INDEX idx_jobs_status ON jobs(status);

-- ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ 
CREATE TABLE unique_frames (
    id SERIAL PRIMARY KEY,
    job_id UUID REFERENCES jobs(id) ON DELETE CASCADE,
    frame_index INTEGER NOT NULL,
    thumbnail_url TEXT,
    pose_landmarks JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(job_id, frame_index)
);

CREATE INDEX idx_unique_frames_job_id ON unique_frames(job_id);

-- ç”Ÿæˆå‹•ç”»
CREATE TABLE generated_videos (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    job_id UUID REFERENCES jobs(id) ON DELETE CASCADE,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    video_url TEXT NOT NULL,
    file_size_bytes BIGINT,
    duration_seconds FLOAT,
    views_count INTEGER DEFAULT 0,
    is_public BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_generated_videos_user_id ON generated_videos(user_id);
CREATE INDEX idx_generated_videos_public ON generated_videos(is_public) WHERE is_public = TRUE;
```

---

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

### è„…å¨ãƒ¢ãƒ‡ãƒ«

| è„…å¨ | å¯¾ç­– | å®Ÿè£…ç®‡æ‰€ |
|------|------|---------|
| **æ‚ªæ„ã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** | MIMEã‚¿ã‚¤ãƒ—æ¤œè¨¼ã€ã‚µã‚¤ã‚ºåˆ¶é™ã€FFprobeæ¤œè¨¼ | FastAPI middleware |
| **DoSæ”»æ’ƒ** | Rate limiting (10 req/min/IP) | Middleware |
| **XSS** | CSP ãƒ˜ãƒƒãƒ€ãƒ¼ã€å…¥åŠ›ã‚µãƒ‹ã‚¿ã‚¤ã‚º | Next.js headers |
| **CSRF** | SameSite cookiesã€CORSè¨­å®š | FastAPI CORS middleware |
| **ãƒ‡ãƒ¼ã‚¿æ¼æ´©** | ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•å‰Šé™¤ã€ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒ§ãƒ–ID | Cron job |

### å®Ÿè£…ä¾‹

```python
# packages/backend/app/middleware/security.py

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
import magic
import hashlib
from pathlib import Path

# Rate limiter
limiter = Limiter(key_func=get_remote_address)

async def rate_limit_middleware(request: Request, call_next):
    """
    Rate limiting middleware
    """
    # /api/* ã«å¯¾ã—ã¦10 req/min/IP
    if request.url.path.startswith("/api/"):
        # slowapi limiterã§å‡¦ç†
        pass

    response = await call_next(request)
    return response

async def file_validation_middleware(request: Request, call_next):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¤œè¨¼
    """
    if request.url.path == "/api/upload" and request.method == "POST":
        # Content-Type ãƒã‚§ãƒƒã‚¯
        content_type = request.headers.get("content-type", "")
        if not content_type.startswith("multipart/form-data"):
            return JSONResponse(
                status_code=400,
                content={"detail": "Invalid content type"}
            )

    response = await call_next(request)
    return response

def validate_video_file(file_path: str) -> bool:
    """
    å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æ¤œè¨¼

    - MIMEã‚¿ã‚¤ãƒ—ï¼ˆlibmagicä½¿ç”¨ï¼‰
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
    - FFprobe ã«ã‚ˆã‚‹æ§‹é€ æ¤œè¨¼
    """
    path = Path(file_path)

    # MIMEã‚¿ã‚¤ãƒ—æ¤œè¨¼ï¼ˆå®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‹ã‚‰åˆ¤å®šï¼‰
    mime = magic.Magic(mime=True)
    file_mime = mime.from_file(file_path)

    if file_mime not in ["video/mp4", "video/quicktime", "image/gif"]:
        return False

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
    if path.stat().st_size > 100 * 1024 * 1024:  # 100MB
        return False

    # FFprobeæ¤œè¨¼ï¼ˆmalformed fileã‚’æ¤œå‡ºï¼‰
    try:
        probe = ffmpeg.probe(file_path)
        if 'streams' not in probe or len(probe['streams']) == 0:
            return False
    except ffmpeg.Error:
        return False

    return True

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
SECURITY_HEADERS = {
    "X-Content-Type-Options": "nosniff",
    "X-Frame-Options": "DENY",
    "X-XSS-Protection": "1; mode=block",
    "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
    "Content-Security-Policy": "default-src 'self'; script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline'; img-src 'self' data: blob:; media-src 'self' blob:;"
}

async def security_headers_middleware(request: Request, call_next):
    """
    ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 
    """
    response = await call_next(request)
    for header, value in SECURITY_HEADERS.items():
        response.headers[header] = value
    return response
```

### CORSè¨­å®š

```python
# packages/backend/app/main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.config import settings

app = FastAPI(title="DanceFrame API", version="2.0")

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,  # ["http://localhost:3000", "https://danceframe.app"]
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
    max_age=3600,
)
```

---

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### Frontendæœ€é©åŒ–

#### 1. React Compilerï¼ˆè‡ªå‹•æœ€é©åŒ–ï¼‰

```javascript
// next.config.js

/** @type {import('next').NextConfig} */
const nextConfig = {
  experimental: {
    reactCompiler: true  // React Compileræœ‰åŠ¹åŒ–
  },
  // Turbopack (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹)
}

module.exports = nextConfig
```

#### 2. ç”»åƒæœ€é©åŒ–

```typescript
// packages/frontend/src/components/review/ThumbnailGrid.tsx

import Image from 'next/image';

export function ThumbnailGrid({ frames }: { frames: CapturedFrame[] }) {
  return (
    <div className="grid grid-cols-4 gap-4">
      {frames.map((frame) => (
        <div key={frame.id} className="relative aspect-square">
          <Image
            src={frame.thumbnail}
            alt={`Frame ${frame.id}`}
            fill
            sizes="(max-width: 768px) 50vw, 25vw"
            className="object-cover rounded-lg"
            priority={frame.id < 4}  // æœ€åˆã®4æšã¯å„ªå…ˆèª­ã¿è¾¼ã¿
          />
        </div>
      ))}
    </div>
  );
}
```

#### 3. Code Splitting

```typescript
// packages/frontend/src/app/capture/page.tsx

import dynamic from 'next/dynamic';

// MediaPipeã¯é‡ã„ã®ã§é…å»¶ãƒ­ãƒ¼ãƒ‰
const CameraView = dynamic(
  () => import('@/components/camera/CameraView').then(mod => mod.CameraView),
  {
    loading: () => <div>Loading camera...</div>,
    ssr: false  // ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã§ã¯å®Ÿè¡Œã—ãªã„
  }
);

export default function CapturePage() {
  return <CameraView />;
}
```

### Backendæœ€é©åŒ–

#### 1. Celeryãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®š

```python
# docker-compose.yml

services:
  celery-worker:
    image: danceframe-backend
    command: celery -A app.celery_worker worker --loglevel=info --concurrency=2 --max-tasks-per-child=50
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    deploy:
      replicas: 2  # 2ã¤ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ä¸¦åˆ—å®Ÿè¡Œ
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
```

#### 2. Redisè¨­å®šæœ€é©åŒ–

```conf
# redis.conf

maxmemory 2gb
maxmemory-policy allkeys-lru  # LRUã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤

# AOF persistenceï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
appendonly no  # æ®ç™ºæ€§ã§OKãªã®ã§ã‚ªãƒ•

# RDB snapshotï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
save ""  # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç„¡åŠ¹

# TCP backlog
tcp-backlog 511

# Timeout
timeout 300
```

#### 3. FFmpegæœ€é©åŒ–

```python
# GPUåŠ é€Ÿå¯¾å¿œï¼ˆNVIDIAã®å ´åˆï¼‰
def create_video_with_gpu(frames_dir, output_path, fps=24):
    """
    NVIDIA GPUåŠ é€Ÿã‚’ä½¿ç”¨ã—ãŸå‹•ç”»ç”Ÿæˆ
    """
    stream = (
        ffmpeg
        .input(str(frames_dir / "frame_%04d.png"), framerate=fps)
        .output(
            output_path,
            vcodec='h264_nvenc',  # NVIDIA GPU encoder
            pix_fmt='yuv420p',
            preset='p4',  # p1-p7 (é«˜é€Ÿ â†’ é«˜å“è³ª)
            rc='vbr',  # Variable bitrate
            cq=23,  # Constant quality
            gpu=0  # GPU ID
        )
        .overwrite_output()
    )

    ffmpeg.run(stream)
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

### å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

1. **MediaPipe Tasks Vision**
   - URL: https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker/web_js
   - æœ€çµ‚ç¢ºèª: 2025-01-13

2. **Next.js 16 Documentation**
   - URL: https://nextjs.org/docs
   - Release Notes: https://nextjs.org/blog/next-16

3. **React 19.2 Documentation**
   - URL: https://react.dev/
   - Compiler: https://react.dev/learn/react-compiler

4. **FastAPI Best Practices**
   - URL: https://fastapi.tiangolo.com/
   - GitHub: https://github.com/zhanymkanov/fastapi-best-practices

5. **Celery Documentation**
   - URL: https://docs.celeryproject.org/
   - Best Practices: https://docs.celeryproject.org/en/stable/userguide/tasks.html

6. **FFmpeg Documentation**
   - URL: https://ffmpeg.org/documentation.html
   - Python Bindings: https://kkroening.github.io/ffmpeg-python/

### æŠ€è¡“è¨˜äº‹

- [Building a Video Processing Pipeline using FastAPI, Celery, and Redis](https://medium.com/@hemantgarg26/building-a-video-processing-pipeline-using-fastapi-celery-and-redis-e045dcf66c7f)
- [State Management in 2025: When to Use Zustand](https://dev.to/hijazi313/state-management-in-2025)
- [MediaPipe Migration Guide](https://developers.google.com/mediapipe/solutions/guide)

---

**Document Version**: 2.0
**Last Updated**: 2025-11-16
**Next Review**: 2025-12-16
